{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Sentiment Analysis of Yelp Reviews\n",
    "## Author: Robert Surridge"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rsurridge/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load the dataset with a sample of 100,000 Yelp reviews, explore the metadata, and add a column \"length\" that contains the number of words per review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of the dataset: (100000, 10)\n",
      "\n",
      "Dataset Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>100000</td>\n",
       "      <td>79345</td>\n",
       "      <td>9973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99964</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>KU_O5udG6zpxOg-VcAEodg</td>\n",
       "      <td>_BcWyKQL16ndpBdggh2kNA</td>\n",
       "      <td>GBTPC53ZrG1ZBY3DT8Mbcw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Service was a little slow to start but improve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.842910</td>\n",
       "      <td>0.898980</td>\n",
       "      <td>0.257180</td>\n",
       "      <td>0.347030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-05-02 14:36:08.625299968</td>\n",
       "      <td>548.438330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2005-03-01 17:47:15</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-12-07 13:33:34.750000128</td>\n",
       "      <td>226.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-26 23:21:59.500000</td>\n",
       "      <td>395.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-04-08 12:26:05.249999872</td>\n",
       "      <td>693.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-10-04 18:22:35</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.354729</td>\n",
       "      <td>2.205186</td>\n",
       "      <td>1.010212</td>\n",
       "      <td>1.066382</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>501.703274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     review_id                 user_id   \n",
       "count                   100000                  100000  \\\n",
       "unique                  100000                   79345   \n",
       "top     KU_O5udG6zpxOg-VcAEodg  _BcWyKQL16ndpBdggh2kNA   \n",
       "freq                         1                      65   \n",
       "mean                       NaN                     NaN   \n",
       "min                        NaN                     NaN   \n",
       "25%                        NaN                     NaN   \n",
       "50%                        NaN                     NaN   \n",
       "75%                        NaN                     NaN   \n",
       "max                        NaN                     NaN   \n",
       "std                        NaN                     NaN   \n",
       "\n",
       "                   business_id          stars         useful          funny   \n",
       "count                   100000  100000.000000  100000.000000  100000.000000  \\\n",
       "unique                    9973            NaN            NaN            NaN   \n",
       "top     GBTPC53ZrG1ZBY3DT8Mbcw            NaN            NaN            NaN   \n",
       "freq                       950            NaN            NaN            NaN   \n",
       "mean                       NaN       3.842910       0.898980       0.257180   \n",
       "min                        NaN       1.000000       0.000000       0.000000   \n",
       "25%                        NaN       3.000000       0.000000       0.000000   \n",
       "50%                        NaN       4.000000       0.000000       0.000000   \n",
       "75%                        NaN       5.000000       1.000000       0.000000   \n",
       "max                        NaN       5.000000     320.000000      98.000000   \n",
       "std                        NaN       1.354729       2.205186       1.010212   \n",
       "\n",
       "                 cool                                               text   \n",
       "count   100000.000000                                             100000  \\\n",
       "unique            NaN                                              99964   \n",
       "top               NaN  Service was a little slow to start but improve...   \n",
       "freq              NaN                                                  2   \n",
       "mean         0.347030                                                NaN   \n",
       "min          0.000000                                                NaN   \n",
       "25%          0.000000                                                NaN   \n",
       "50%          0.000000                                                NaN   \n",
       "75%          0.000000                                                NaN   \n",
       "max         49.000000                                                NaN   \n",
       "std          1.066382                                                NaN   \n",
       "\n",
       "                                 date         length  \n",
       "count                          100000  100000.000000  \n",
       "unique                            NaN            NaN  \n",
       "top                               NaN            NaN  \n",
       "freq                              NaN            NaN  \n",
       "mean    2015-05-02 14:36:08.625299968     548.438330  \n",
       "min               2005-03-01 17:47:15       3.000000  \n",
       "25%     2013-12-07 13:33:34.750000128     226.000000  \n",
       "50%        2015-09-26 23:21:59.500000     395.000000  \n",
       "75%     2017-04-08 12:26:05.249999872     693.000000  \n",
       "max               2018-10-04 18:22:35    5000.000000  \n",
       "std                               NaN     501.703274  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_data = pd.read_json('/Users/rsurridge/Downloads/yelp_data/yelp_academic_dataset_review.json', \n",
    "                         lines=True, chunksize=100_000)\n",
    "for chunk in yelp_data:\n",
    "    yelp_sample_unequal = chunk\n",
    "    result = chunk.to_json(orient=\"records\")\n",
    "    with open(\"yelp_sample.json\", \"w\") as f:\n",
    "        json.dump(result, f)\n",
    "    break\n",
    "\n",
    "yelp_sample_unequal['length'] = yelp_sample_unequal['text'].apply(len)\n",
    "yelp_sample_unequal['stars'] = yelp_sample_unequal['stars'].astype(float)\n",
    "\n",
    "print()\n",
    "print(\"Shape of the dataset:\", yelp_sample_unequal.shape)\n",
    "\n",
    "print()\n",
    "print(\"Dataset Summary:\")\n",
    "yelp_sample_unequal.describe(include='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of possible words: 67824\n",
      "\n",
      "Return unigram word from index 5000: assaults\n",
      "Return unigram word from index 20000: easiest\n",
      "\n",
      "Number of possible words: 1976754\n",
      "\n",
      "Return unigram word from index 5000: 12 terms\n",
      "Return unigram word from index 20000: 550 calories\n",
      "\n",
      "Number of possible words: 3934118\n",
      "\n",
      "Return unigram word from index 5000: 10 people group\n",
      "Return unigram word from index 20000: 20 uhh did\n"
     ]
    }
   ],
   "source": [
    "unigram_vocab = (CountVectorizer(ngram_range=(1,1), stop_words='english')\n",
    "                 .fit(yelp_sample_unequal.loc[:, 'text']))\n",
    "\n",
    "print()\n",
    "print(\"Number of possible words:\", len(unigram_vocab.vocabulary_))\n",
    "\n",
    "print()\n",
    "print(\"Return unigram word from index 5000:\", \n",
    "      unigram_vocab.get_feature_names_out()[5000])\n",
    "print(\"Return unigram word from index 20000:\", \n",
    "      unigram_vocab.get_feature_names_out()[20000])\n",
    "\n",
    "bigram_vocab = (CountVectorizer(ngram_range = (2, 2), stop_words='english')\n",
    "                .fit(yelp_sample_unequal.loc[:, 'text']))\n",
    "\n",
    "print()\n",
    "print(\"Number of possible words:\", len(bigram_vocab.vocabulary_))\n",
    "\n",
    "print()\n",
    "print(\"Return unigram word from index 5000:\", \n",
    "      bigram_vocab.get_feature_names_out()[5000])\n",
    "print(\"Return unigram word from index 20000:\", \n",
    "      bigram_vocab.get_feature_names_out()[20000])\n",
    "\n",
    "trigram_vocab = (CountVectorizer(ngram_range = (3, 3), stop_words='english')\n",
    "                .fit(yelp_sample_unequal.loc[:, 'text']))\n",
    "\n",
    "print()\n",
    "print(\"Number of possible words:\", len(trigram_vocab.vocabulary_))\n",
    "\n",
    "print()\n",
    "print(\"Return unigram word from index 5000:\", \n",
    "      trigram_vocab.get_feature_names_out()[5000])\n",
    "print(\"Return unigram word from index 20000:\", \n",
    "      trigram_vocab.get_feature_names_out()[20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of the dataset: (100000, 2)\n",
      "\n",
      "Unequal star count (100,000 reviews)\n",
      "stars\n",
      "5.0    44392\n",
      "4.0    25337\n",
      "3.0    11362\n",
      "1.0    10921\n",
      "2.0     7988\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Equal star count (100,000 reviews)\n",
      "stars\n",
      "1.0    7988\n",
      "2.0    7988\n",
      "3.0    7988\n",
      "4.0    7988\n",
      "5.0    7988\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "yelp_classify = yelp_sample_unequal.loc[:, ['stars', 'text']]\n",
    "\n",
    "print()\n",
    "print(\"Shape of the dataset:\", yelp_classify.shape)\n",
    "\n",
    "x_unequal = yelp_classify['text']\n",
    "y_unequal = yelp_classify['stars']\n",
    "\n",
    "unequal_count = y_unequal.value_counts()\n",
    "min_count = unequal_count.min()\n",
    "yelp_sample_equal = (yelp_sample_unequal.groupby('stars').apply(lambda x: x[:min_count]))\n",
    "equal_count = yelp_sample_equal['stars'].value_counts()\n",
    "\n",
    "x_equal = yelp_sample_equal['text']\n",
    "y_equal = yelp_sample_equal['stars']\n",
    "\n",
    "print()\n",
    "print(\"Unequal star count (100,000 reviews)\")\n",
    "print(unequal_count)\n",
    "\n",
    "print()\n",
    "print(\"Equal star count (100,000 reviews)\")\n",
    "print(equal_count)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Plot histograms of review length frenquencies by the star rating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Star Rating Frequency with a RAW Sample of One Million Reviews')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_star_freq_raw = plt.hist(yelp_sample_unequal['stars'], bins=5, color='blue')\n",
    "plt.title('Star Rating Frequency with a RAW Sample of One Million Reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Star Rating Frequency with a NORMALIZED Sample of One Million Reviews')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_star_freq_normal = plt.hist(yelp_sample_equal['stars'], bins=5, color='blue')\n",
    "plt.title('Star Rating Frequency with a NORMALIZED Sample of One Million Reviews')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to note here that our sample dataset is biased to more positive reviews than negative reviews. As a result, we should proceed with caution when classifying, training, and predicting with this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Classify reviews into different star classes and separate the dataset into X and Y subsets for prediction:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.i.i. 100,000 equal reviews into 1-star (negative), 2-star (negative), 3-star (neutral), 4-star (positive), and 5-star (positive) classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of the dataset: (39940, 2)\n"
     ]
    }
   ],
   "source": [
    "yelp_classify = yelp_sample_equal.loc[:, ['stars', 'text']]\n",
    "\n",
    "print()\n",
    "print(\"Shape of the dataset:\", yelp_classify.shape)\n",
    "\n",
    "x_five_equal = yelp_classify['text']\n",
    "y_five_equal = yelp_classify['stars']\n",
    "\n",
    "unigram_five_equal = unigram_vocab.transform(x_five_equal)\n",
    "(x_train_five_equal_unigram, \n",
    " x_test_five_equal_unigram, \n",
    " y_train_five_equal_unigram, \n",
    " y_test_five_equal_unigram) = train_test_split(unigram_five_equal, \n",
    "                                                 y_five_equal, \n",
    "                                                 test_size=0.2, \n",
    "                                                 random_state=101)\n",
    "\n",
    "bigram_five_equal = bigram_vocab.transform(x_five_equal)\n",
    "(x_train_five_equal_bigram, \n",
    " x_test_five_equal_bigram, \n",
    " y_train_five_equal_bigram, \n",
    " y_test_five_equal_bigram) = train_test_split(bigram_five_equal, \n",
    "                                                 y_five_equal, \n",
    "                                                 test_size=0.2, \n",
    "                                                 random_state=101)\n",
    "\n",
    "\n",
    "trigram_five_equal = trigram_vocab.transform(x_five_equal)\n",
    "(x_train_five_equal_trigram, \n",
    " x_test_five_equal_trigram, \n",
    " y_train_five_equal_trigram, \n",
    " y_test_five_equal_trigram) = train_test_split(trigram_five_equal, \n",
    "                                               y_five_equal, \n",
    "                                               test_size=0.2, \n",
    "                                               random_state=101)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.i.ii. 100,000 unequal reviews into 1-star (negative), 2-star (negative), 3-star (neutral), 4-star (positive), and 5-star (positive) classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of the dataset: (100000, 2)\n"
     ]
    }
   ],
   "source": [
    "yelp_classify = yelp_sample_unequal.loc[:, ['stars', 'text']]\n",
    "\n",
    "print()\n",
    "print(\"Shape of the dataset:\", yelp_classify.shape)\n",
    "\n",
    "x_five_unequal = yelp_classify['text']\n",
    "y_five_unequal = yelp_classify['stars']\n",
    "\n",
    "unigram_five_unequal = unigram_vocab.transform(x_five_unequal)\n",
    "(x_train_five_unequal_unigram, \n",
    " x_test_five_unequal_unigram, \n",
    " y_train_five_unequal_unigram, \n",
    " y_test_five_unequal_unigram) = train_test_split(unigram_five_unequal, \n",
    "                                                 y_five_unequal, \n",
    "                                                 test_size=0.2, \n",
    "                                                 random_state=101)\n",
    "\n",
    "bigram_five_unequal = bigram_vocab.transform(x_five_unequal)\n",
    "(x_train_five_unequal_bigram, \n",
    " x_test_five_unequal_bigram, \n",
    " y_train_five_unequal_bigram, \n",
    " y_test_five_unequal_bigram) = train_test_split(bigram_five_unequal, \n",
    "                                                 y_five_unequal, \n",
    "                                                 test_size=0.2, \n",
    "                                                 random_state=101)\n",
    "\n",
    "\n",
    "trigram_five_unequal = trigram_vocab.transform(x_five_unequal)\n",
    "(x_train_five_unequal_trigram, \n",
    " x_test_five_unequal_trigram, \n",
    " y_train_five_unequal_trigram, \n",
    " y_test_five_unequal_trigram) = train_test_split(trigram_five_unequal, \n",
    "                                               y_five_unequal, \n",
    "                                               test_size=0.2, \n",
    "                                               random_state=101)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.ii.i. 100,000 equal reviews into 1-star (negative) and 5-star (positive) classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of the dataset: (15976, 2)\n"
     ]
    }
   ],
   "source": [
    "yelp_classify = yelp_sample_equal.loc[:, ['stars', 'text']]\n",
    "data_classes = yelp_classify[(yelp_classify['stars']==1) | \n",
    "                           (yelp_classify['stars']==5)]\n",
    "\n",
    "print()\n",
    "print(\"Shape of the dataset:\", data_classes.shape)\n",
    "\n",
    "x_two_equal = data_classes['text']\n",
    "y_two_equal = data_classes['stars']\n",
    "\n",
    "unigram_two_equal = unigram_vocab.transform(x_two_equal)\n",
    "(x_train_two_equal_unigram, \n",
    " x_test_two_equal_unigram, \n",
    " y_train_two_equal_unigram, \n",
    " y_test_two_equal_unigram) = train_test_split(unigram_two_equal, \n",
    "                                                 y_two_equal, \n",
    "                                                 test_size=0.2, \n",
    "                                                 random_state=101)\n",
    "\n",
    "bigram_two_equal = bigram_vocab.transform(x_two_equal)\n",
    "(x_train_two_equal_bigram, \n",
    " x_test_two_equal_bigram, \n",
    " y_train_two_equal_bigram, \n",
    " y_test_two_equal_bigram) = train_test_split(bigram_two_equal, \n",
    "                                                 y_two_equal, \n",
    "                                                 test_size=0.2, \n",
    "                                                 random_state=101)\n",
    "\n",
    "\n",
    "trigram_two_equal = trigram_vocab.transform(x_two_equal)\n",
    "(x_train_two_equal_trigram, \n",
    " x_test_two_equal_trigram, \n",
    " y_train_two_equal_trigram, \n",
    " y_test_two_equal_trigram) = train_test_split(trigram_two_equal, \n",
    "                                               y_two_equal, \n",
    "                                               test_size=0.2, \n",
    "                                               random_state=101)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.ii.ii. 100,000 unequal reviews into 1-star (negative) and 5-star (positive) classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of the dataset: (55313, 2)\n"
     ]
    }
   ],
   "source": [
    "yelp_classify = yelp_sample_unequal.loc[:, ['stars', 'text']]\n",
    "data_classes = yelp_classify[(yelp_classify['stars']==1) | \n",
    "                           (yelp_classify['stars']==5)]\n",
    "\n",
    "print()\n",
    "print(\"Shape of the dataset:\", data_classes.shape)\n",
    "\n",
    "x_two_unequal = data_classes['text']\n",
    "y_two_unequal = data_classes['stars']\n",
    "\n",
    "unigram_two_unequal = unigram_vocab.transform(x_two_unequal)\n",
    "(x_train_two_unequal_unigram, \n",
    " x_test_two_unequal_unigram, \n",
    " y_train_two_unequal_unigram, \n",
    " y_test_two_unequal_unigram) = train_test_split(unigram_two_unequal, \n",
    "                                                 y_two_unequal, \n",
    "                                                 test_size=0.2, \n",
    "                                                 random_state=101)\n",
    "\n",
    "bigram_two_unequal = bigram_vocab.transform(x_two_unequal)\n",
    "(x_train_two_unequal_bigram, \n",
    " x_test_two_unequal_bigram, \n",
    " y_train_two_unequal_bigram, \n",
    " y_test_two_unequal_bigram) = train_test_split(bigram_two_unequal, \n",
    "                                                 y_two_unequal, \n",
    "                                                 test_size=0.2, \n",
    "                                                 random_state=101)\n",
    "\n",
    "\n",
    "trigram_two_unequal = trigram_vocab.transform(x_two_unequal)\n",
    "(x_train_two_unequal_trigram, \n",
    " x_test_two_unequal_trigram, \n",
    " y_train_two_unequal_trigram, \n",
    " y_test_two_unequal_trigram) = train_test_split(trigram_two_unequal, \n",
    "                                               y_two_unequal, \n",
    "                                               test_size=0.2, \n",
    "                                               random_state=101)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.iii.i. 100,000 equal reviews into 1-star (negative), 3-star (neutral), and 5-star (positive) classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of the dataset: (23964, 2)\n"
     ]
    }
   ],
   "source": [
    "yelp_classify = yelp_sample_equal.loc[:, ['stars', 'text']]\n",
    "data_classes = yelp_classify[(yelp_classify['stars']==1) | \n",
    "                           (yelp_classify['stars']==3) | \n",
    "                           (yelp_classify['stars']==5)]\n",
    "\n",
    "print()\n",
    "print(\"Shape of the dataset:\", data_classes.shape)\n",
    "\n",
    "x_three_equal = data_classes['text']\n",
    "y_three_equal = data_classes['stars']\n",
    "\n",
    "unigram_three_equal = unigram_vocab.transform(x_three_equal)\n",
    "(x_train_three_equal_unigram, \n",
    " x_test_three_equal_unigram, \n",
    " y_train_three_equal_unigram, \n",
    " y_test_three_equal_unigram) = train_test_split(unigram_three_equal, \n",
    "                                                 y_three_equal, \n",
    "                                                 test_size=0.2, \n",
    "                                                 random_state=101)\n",
    "\n",
    "bigram_three_equal = bigram_vocab.transform(x_three_equal)\n",
    "(x_train_three_equal_bigram, \n",
    " x_test_three_equal_bigram, \n",
    " y_train_three_equal_bigram, \n",
    " y_test_three_equal_bigram) = train_test_split(bigram_three_equal, \n",
    "                                                 y_three_equal, \n",
    "                                                 test_size=0.2, \n",
    "                                                 random_state=101)\n",
    "\n",
    "\n",
    "trigram_three_equal = trigram_vocab.transform(x_three_equal)\n",
    "(x_train_three_equal_trigram, \n",
    " x_test_three_equal_trigram, \n",
    " y_train_three_equal_trigram, \n",
    " y_test_three_equal_trigram) = train_test_split(trigram_three_equal, \n",
    "                                               y_three_equal, \n",
    "                                               test_size=0.2, \n",
    "                                               random_state=101)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.iii.ii. 100,000 unequal reviews into 1-star (negative), 3-star (neutral), and 5-star (positive) classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of the dataset: (66675, 2)\n"
     ]
    }
   ],
   "source": [
    "yelp_classify = yelp_sample_unequal.loc[:, ['stars', 'text']]\n",
    "data_classes = yelp_classify[(yelp_classify['stars']==1) | \n",
    "                           (yelp_classify['stars']==3) | \n",
    "                           (yelp_classify['stars']==5)]\n",
    "\n",
    "print()\n",
    "print(\"Shape of the dataset:\", data_classes.shape)\n",
    "\n",
    "x_three_unequal = data_classes['text']\n",
    "y_three_unequal = data_classes['stars']\n",
    "\n",
    "unigram_three_unequal = unigram_vocab.transform(x_three_unequal)\n",
    "(x_train_three_unequal_unigram, \n",
    " x_test_three_unequal_unigram, \n",
    " y_train_three_unequal_unigram, \n",
    " y_test_three_unequal_unigram) = train_test_split(unigram_three_unequal, \n",
    "                                                 y_three_unequal, \n",
    "                                                 test_size=0.2, \n",
    "                                                 random_state=101)\n",
    "\n",
    "bigram_three_unequal = bigram_vocab.transform(x_three_unequal)\n",
    "(x_train_three_unequal_bigram, \n",
    " x_test_three_unequal_bigram, \n",
    " y_train_three_unequal_bigram, \n",
    " y_test_three_unequal_bigram) = train_test_split(bigram_three_unequal, \n",
    "                                                 y_three_unequal, \n",
    "                                                 test_size=0.2, \n",
    "                                                 random_state=101)\n",
    "\n",
    "\n",
    "trigram_three_unequal = trigram_vocab.transform(x_three_unequal)\n",
    "(x_train_three_unequal_trigram, \n",
    " x_test_three_unequal_trigram, \n",
    " y_train_three_unequal_trigram, \n",
    " y_test_three_unequal_trigram) = train_test_split(trigram_three_unequal, \n",
    "                                                  y_three_unequal, \n",
    "                                                  test_size=0.2, \n",
    "                                                  random_state=101)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Vectorize reviews and split processed dataset into training and testing sets:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Modeling reviews with Multinomial Naive Bayes (since we're working with sparse data, we cannot rely on the Gaussian Naive Bayes assumptions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.i.i. 100,000 (1-star, 2-star, 3-star, 4-star, and 5-star) equal reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unigram Score: 51.09\n",
      "\n",
      "Unigram Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.62      0.65      0.63      1626\n",
      "         2.0       0.44      0.44      0.44      1584\n",
      "         3.0       0.42      0.47      0.44      1650\n",
      "         4.0       0.45      0.49      0.47      1596\n",
      "         5.0       0.69      0.51      0.58      1532\n",
      "\n",
      "    accuracy                           0.51      7988\n",
      "   macro avg       0.52      0.51      0.51      7988\n",
      "weighted avg       0.52      0.51      0.51      7988\n",
      "\n",
      "\n",
      "Bigram Score: 49.07\n",
      "\n",
      "Bigram Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.66      0.61      0.64      1626\n",
      "         2.0       0.43      0.48      0.45      1584\n",
      "         3.0       0.40      0.47      0.43      1650\n",
      "         4.0       0.41      0.42      0.42      1596\n",
      "         5.0       0.61      0.47      0.53      1532\n",
      "\n",
      "    accuracy                           0.49      7988\n",
      "   macro avg       0.50      0.49      0.49      7988\n",
      "weighted avg       0.50      0.49      0.49      7988\n",
      "\n",
      "\n",
      "Trigram Score: 33.84\n",
      "\n",
      "Trigram Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.58      0.34      0.43      1626\n",
      "         2.0       0.38      0.22      0.28      1584\n",
      "         3.0       0.33      0.21      0.26      1650\n",
      "         4.0       0.31      0.29      0.30      1596\n",
      "         5.0       0.28      0.64      0.39      1532\n",
      "\n",
      "    accuracy                           0.34      7988\n",
      "   macro avg       0.38      0.34      0.33      7988\n",
      "weighted avg       0.38      0.34      0.33      7988\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb_5 = MultinomialNB()\n",
    "mnb_5.fit(x_train_five_equal_unigram, y_train_five_equal_unigram)\n",
    "predmnb = mnb_5.predict(x_test_five_equal_unigram)\n",
    "\n",
    "print()\n",
    "print(\"Unigram Score:\", round(accuracy_score(y_test_five_equal_unigram, predmnb) * 100, 2))\n",
    "\n",
    "print()\n",
    "print(\"Unigram Classification Report:\")\n",
    "print(classification_report(y_test_five_equal_unigram, predmnb))\n",
    "\n",
    "mnb_5.fit(x_train_five_equal_bigram, y_train_five_equal_bigram)\n",
    "predmnb = mnb_5.predict(x_test_five_equal_bigram)\n",
    "\n",
    "print()\n",
    "print(\"Bigram Score:\", round(accuracy_score(y_test_five_equal_bigram, predmnb) * 100, 2))\n",
    "\n",
    "print()\n",
    "print(\"Bigram Classification Report:\")\n",
    "print(classification_report(y_test_five_equal_bigram, predmnb))\n",
    "\n",
    "mnb_5.fit(x_train_five_equal_trigram, y_train_five_equal_trigram)\n",
    "predmnb = mnb_5.predict(x_test_five_equal_trigram)\n",
    "\n",
    "print()\n",
    "print(\"Trigram Score:\", round(accuracy_score(y_test_five_equal_trigram, predmnb) * 100, 2))\n",
    "\n",
    "print()\n",
    "print(\"Trigram Classification Report:\")\n",
    "print(classification_report(y_test_five_equal_trigram, predmnb))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.i.ii. 100,000 (1-star, 2-star, 3-star, 4-star, and 5-star) unequal reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unigram Score: 58.44\n",
      "\n",
      "Unigram Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.58      0.69      0.63      2168\n",
      "         2.0       0.36      0.22      0.27      1566\n",
      "         3.0       0.38      0.26      0.31      2339\n",
      "         4.0       0.45      0.56      0.50      5026\n",
      "         5.0       0.76      0.74      0.75      8901\n",
      "\n",
      "    accuracy                           0.59     20000\n",
      "   macro avg       0.51      0.49      0.49     20000\n",
      "weighted avg       0.59      0.59      0.58     20000\n",
      "\n",
      "\n",
      "Bigram Score: 54.61\n",
      "\n",
      "Bigram Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.64      0.67      0.66      2168\n",
      "         2.0       0.31      0.12      0.18      1566\n",
      "         3.0       0.32      0.16      0.21      2339\n",
      "         4.0       0.40      0.46      0.43      5026\n",
      "         5.0       0.69      0.79      0.74      8901\n",
      "\n",
      "    accuracy                           0.57     20000\n",
      "   macro avg       0.47      0.44      0.44     20000\n",
      "weighted avg       0.54      0.57      0.55     20000\n",
      "\n",
      "\n",
      "Trigram Score: 35.59\n",
      "\n",
      "Trigram Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.39      0.38      0.38      2168\n",
      "         2.0       0.11      0.55      0.18      1566\n",
      "         3.0       0.19      0.27      0.22      2339\n",
      "         4.0       0.38      0.20      0.27      5026\n",
      "         5.0       0.74      0.34      0.47      8901\n",
      "\n",
      "    accuracy                           0.32     20000\n",
      "   macro avg       0.36      0.35      0.30     20000\n",
      "weighted avg       0.50      0.32      0.36     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb_5 = MultinomialNB()\n",
    "mnb_5.fit(x_train_five_unequal_unigram, y_train_five_unequal_unigram)\n",
    "predmnb = mnb_5.predict(x_test_five_unequal_unigram)\n",
    "\n",
    "print()\n",
    "print(\"Unigram Score:\", round(f1_score(y_test_five_unequal_unigram, predmnb, average='weighted') * 100, 2))\n",
    "\n",
    "print()\n",
    "print(\"Unigram Classification Report:\")\n",
    "print(classification_report(y_test_five_unequal_unigram, predmnb))\n",
    "\n",
    "mnb_5 = MultinomialNB()\n",
    "mnb_5.fit(x_train_five_unequal_bigram, y_train_five_unequal_bigram)\n",
    "predmnb = mnb_5.predict(x_test_five_unequal_bigram)\n",
    "\n",
    "print()\n",
    "print(\"Bigram Score:\", round(f1_score(y_test_five_unequal_bigram, predmnb, average='weighted') * 100, 2))\n",
    "\n",
    "print()\n",
    "print(\"Bigram Classification Report:\")\n",
    "print(classification_report(y_test_five_unequal_bigram, predmnb))\n",
    "\n",
    "mnb_5 = MultinomialNB()\n",
    "mnb_5.fit(x_train_five_unequal_trigram, y_train_five_unequal_trigram)\n",
    "predmnb = mnb_5.predict(x_test_five_unequal_trigram)\n",
    "\n",
    "print()\n",
    "print(\"Trigram Score:\", round(f1_score(y_test_five_unequal_trigram, predmnb, average='weighted') * 100, 2))\n",
    "\n",
    "print()\n",
    "print(\"Trigram Classification Report:\")\n",
    "print(classification_report(y_test_five_unequal_trigram, predmnb))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.ii.i. Modeling 100,000 (1-star and 5-star) equal reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 94.9\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.94      0.96      0.95      1604\n",
      "         5.0       0.95      0.94      0.95      1592\n",
      "\n",
      "    accuracy                           0.95      3196\n",
      "   macro avg       0.95      0.95      0.95      3196\n",
      "weighted avg       0.95      0.95      0.95      3196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb_hund_2 = MultinomialNB()\n",
    "mnb_hund_2.fit(x_train_hund_thou_two_equal, y_train_hund_thou_two_equal)\n",
    "predmnb = mnb_hund_2.predict(x_test_hund_thou_two_equal)\n",
    "\n",
    "print()\n",
    "print(\"Score:\", round(accuracy_score(y_test_hund_thou_two_equal, predmnb) * 100, 2))\n",
    "\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_hund_thou_two_equal, predmnb))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.ii.ii. 100,000 (1-star and 5-star) unequal reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 95.02\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.86      0.89      0.88      2207\n",
      "         5.0       0.97      0.96      0.97      8856\n",
      "\n",
      "    accuracy                           0.95     11063\n",
      "   macro avg       0.92      0.93      0.92     11063\n",
      "weighted avg       0.95      0.95      0.95     11063\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb_hund_2 = MultinomialNB()\n",
    "mnb_hund_2.fit(x_train_hund_thou_two_unequal, y_train_hund_thou_two_unequal)\n",
    "predmnb = mnb_hund_2.predict(x_test_hund_thou_two_unequal)\n",
    "\n",
    "print()\n",
    "print(\"Score:\", round(f1_score(y_test_hund_thou_two_unequal, predmnb, average='weighted') * 100, 2))\n",
    "\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_hund_thou_two_unequal, predmnb))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.iii.i. 100,000 (1-star, 3-star, and 5-star) equal reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 78.24\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.83      0.80      0.81      1640\n",
      "         3.0       0.68      0.78      0.73      1604\n",
      "         5.0       0.87      0.77      0.81      1549\n",
      "\n",
      "    accuracy                           0.78      4793\n",
      "   macro avg       0.79      0.78      0.78      4793\n",
      "weighted avg       0.79      0.78      0.78      4793\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb_hund_3 = MultinomialNB()\n",
    "mnb_hund_3.fit(x_train_hund_thou_three_equal, y_train_hund_thou_three_equal)\n",
    "predmnb = mnb_hund_3.predict(x_test_hund_thou_three_equal)\n",
    "\n",
    "print()\n",
    "print(\"Score:\", round(accuracy_score(y_test_hund_thou_three_equal, predmnb) * 100, 2))\n",
    "\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_hund_thou_three_equal, predmnb))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.iii.ii. 100,000 (1-star, 3-star, and 5-star) unequal reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 85.12\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.77      0.78      0.77      2231\n",
      "         3.0       0.66      0.62      0.64      2272\n",
      "         5.0       0.92      0.93      0.92      8832\n",
      "\n",
      "    accuracy                           0.85     13335\n",
      "   macro avg       0.78      0.78      0.78     13335\n",
      "weighted avg       0.85      0.85      0.85     13335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb_hund_3 = MultinomialNB()\n",
    "mnb_hund_3.fit(x_train_hund_thou_three_unequal, y_train_hund_thou_three_unequal)\n",
    "predmnb = mnb_hund_3.predict(x_test_hund_thou_three_unequal)\n",
    "\n",
    "print()\n",
    "print(\"Score:\", round(f1_score(y_test_hund_thou_three_unequal, predmnb, average='weighted') * 100, 2))\n",
    "\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_hund_thou_three_unequal, predmnb))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Modeling reviews with Random Forest Classifier:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.i.i. 100,000 (1-star, 2-star, 3-star, 4-star, and 5-star) equal reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 49.41\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.54      0.79      0.64      1626\n",
      "         2.0       0.42      0.31      0.36      1584\n",
      "         3.0       0.45      0.36      0.40      1650\n",
      "         4.0       0.44      0.31      0.37      1596\n",
      "         5.0       0.54      0.70      0.61      1532\n",
      "\n",
      "    accuracy                           0.49      7988\n",
      "   macro avg       0.48      0.50      0.48      7988\n",
      "weighted avg       0.48      0.49      0.47      7988\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rmfr_hund_5 = RandomForestClassifier()\n",
    "rmfr_hund_5.fit(x_train_hund_thou_five_equal, y_train_hund_thou_five_equal)\n",
    "predrmfr = rmfr_hund_5.predict(x_test_hund_thou_five_equal)\n",
    "\n",
    "print()\n",
    "print(\"Score:\", round(accuracy_score(y_test_hund_thou_five_equal, predrmfr) * 100, 2))\n",
    "\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_hund_thou_five_equal, predrmfr))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.i.ii. 100,000 (1-star, 2-star, 3-star, 4-star, and 5-star) unequal reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 46.84\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.69      0.57      0.63      2168\n",
      "         2.0       0.39      0.02      0.04      1566\n",
      "         3.0       0.47      0.06      0.10      2339\n",
      "         4.0       0.40      0.22      0.28      5026\n",
      "         5.0       0.56      0.95      0.71      8901\n",
      "\n",
      "    accuracy                           0.55     20000\n",
      "   macro avg       0.50      0.36      0.35     20000\n",
      "weighted avg       0.51      0.55      0.47     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rmfr_hund_5 = RandomForestClassifier()\n",
    "rmfr_hund_5.fit(x_train_hund_thou_five_unequal, y_train_hund_thou_five_unequal)\n",
    "predrmfr = rmfr_hund_5.predict(x_test_hund_thou_five_unequal)\n",
    "\n",
    "print()\n",
    "print(\"Score:\", round(f1_score(y_test_hund_thou_five_unequal, predrmfr, average='weighted') * 100, 2))\n",
    "\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_hund_thou_five_unequal, predrmfr))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.ii.i. 100,000 (1-star and 5-star) equal reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 93.43\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.91      0.96      0.94      1604\n",
      "         5.0       0.96      0.91      0.93      1592\n",
      "\n",
      "    accuracy                           0.93      3196\n",
      "   macro avg       0.94      0.93      0.93      3196\n",
      "weighted avg       0.94      0.93      0.93      3196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rmfr_hund_2 = RandomForestClassifier()\n",
    "rmfr_hund_2.fit(x_train_hund_thou_two_equal, y_train_hund_thou_two_equal)\n",
    "predrmfr = rmfr_hund_2.predict(x_test_hund_thou_two_equal)\n",
    "\n",
    "print()\n",
    "print(\"Score:\", round(accuracy_score(y_test_hund_thou_two_equal, predrmfr) * 100, 2))\n",
    "\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_hund_thou_two_equal, predrmfr))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.ii.ii. 100,000 (1-star and 5-star) unequal reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 92.28\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.97      0.66      0.79      2207\n",
      "         5.0       0.92      1.00      0.96      8856\n",
      "\n",
      "    accuracy                           0.93     11063\n",
      "   macro avg       0.95      0.83      0.87     11063\n",
      "weighted avg       0.93      0.93      0.92     11063\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rmfr_hund_2 = RandomForestClassifier()\n",
    "rmfr_hund_2.fit(x_train_hund_thou_two_unequal, y_train_hund_thou_two_unequal)\n",
    "predrmfr = rmfr_hund_2.predict(x_test_hund_thou_two_unequal)\n",
    "\n",
    "print()\n",
    "print(\"Score:\", round(f1_score(y_test_hund_thou_two_unequal, predrmfr, average='weighted') * 100, 2))\n",
    "\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_hund_thou_two_unequal, predrmfr))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.iii.i. 100,000 (1-star, 3-star, and 5-star) equal reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 77.88\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.79      0.85      0.82      1640\n",
      "         3.0       0.75      0.67      0.70      1604\n",
      "         5.0       0.79      0.82      0.80      1549\n",
      "\n",
      "    accuracy                           0.78      4793\n",
      "   macro avg       0.78      0.78      0.78      4793\n",
      "weighted avg       0.78      0.78      0.78      4793\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rmfr_hund_3 = RandomForestClassifier()\n",
    "rmfr_hund_3.fit(x_train_hund_thou_three_equal, y_train_hund_thou_three_equal)\n",
    "predrmfr = rmfr_hund_3.predict(x_test_hund_thou_three_equal)\n",
    "\n",
    "print()\n",
    "print(\"Score:\", round(accuracy_score(y_test_hund_thou_three_equal, predrmfr) * 100, 2))\n",
    "\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_hund_thou_three_equal, predrmfr))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.iii.ii. 100,000 (1-star, 3-star, and 5-star) unequal reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 74.76\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.89      0.59      0.71      2231\n",
      "         3.0       0.83      0.19      0.31      2272\n",
      "         5.0       0.77      1.00      0.87      8832\n",
      "\n",
      "    accuracy                           0.79     13335\n",
      "   macro avg       0.83      0.59      0.63     13335\n",
      "weighted avg       0.80      0.79      0.75     13335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rmfr_hund_3 = RandomForestClassifier()\n",
    "rmfr_hund_3.fit(x_train_hund_thou_three_unequal, y_train_hund_thou_three_unequal)\n",
    "predrmfr = rmfr_hund_3.predict(x_test_hund_thou_three_unequal)\n",
    "\n",
    "print()\n",
    "print(\"Score:\", round(f1_score(y_test_hund_thou_three_unequal, predrmfr, average='weighted') * 100, 2))\n",
    "\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_hund_thou_three_unequal, predrmfr))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Modeling reviews with the Decision Tree Classifier:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.i.i. 100,000 (1-star, 2-star, 3-star, 4-star, and 5-star) equal reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 37.52\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.49      0.50      0.50      1626\n",
      "         2.0       0.30      0.29      0.29      1584\n",
      "         3.0       0.32      0.30      0.31      1650\n",
      "         4.0       0.32      0.31      0.31      1596\n",
      "         5.0       0.43      0.48      0.45      1532\n",
      "\n",
      "    accuracy                           0.38      7988\n",
      "   macro avg       0.37      0.38      0.37      7988\n",
      "weighted avg       0.37      0.38      0.37      7988\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_hund_5 = DecisionTreeClassifier()\n",
    "dt_hund_5.fit(x_train_hund_thou_five_equal, y_train_hund_thou_five_equal)\n",
    "preddt = dt_hund_5.predict(x_test_hund_thou_five_equal)\n",
    "\n",
    "print()\n",
    "print(\"Score:\", round(accuracy_score(y_test_hund_thou_five_equal, preddt) * 100, 2))\n",
    "\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_hund_thou_five_equal, preddt))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.i.ii. 100,000 (1-star, 2-star, 3-star, 4-star, and 5-star) unequal reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 46.37\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.49      0.50      0.50      2168\n",
      "         2.0       0.21      0.18      0.19      1566\n",
      "         3.0       0.24      0.20      0.22      2339\n",
      "         4.0       0.34      0.33      0.33      5026\n",
      "         5.0       0.62      0.66      0.64      8901\n",
      "\n",
      "    accuracy                           0.47     20000\n",
      "   macro avg       0.38      0.37      0.38     20000\n",
      "weighted avg       0.46      0.47      0.46     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_hund_5 = DecisionTreeClassifier()\n",
    "dt_hund_5.fit(x_train_hund_thou_five_unequal, y_train_hund_thou_five_unequal)\n",
    "preddt = dt_hund_5.predict(x_test_hund_thou_five_unequal)\n",
    "\n",
    "print()\n",
    "print(\"Score:\", round(f1_score(y_test_hund_thou_five_unequal, preddt, average='weighted') * 100, 2))\n",
    "\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_hund_thou_five_unequal, preddt))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.ii.i. 100,000 (1-star and 5-star) equal reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 85.67\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.86      0.86      0.86      1604\n",
      "         5.0       0.85      0.86      0.86      1592\n",
      "\n",
      "    accuracy                           0.86      3196\n",
      "   macro avg       0.86      0.86      0.86      3196\n",
      "weighted avg       0.86      0.86      0.86      3196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_hund_2 = DecisionTreeClassifier()\n",
    "dt_hund_2.fit(x_train_hund_thou_two_equal, y_train_hund_thou_two_equal)\n",
    "preddt = dt_hund_2.predict(x_test_hund_thou_two_equal)\n",
    "\n",
    "print()\n",
    "print(\"Score:\", round(accuracy_score(y_test_hund_thou_two_equal, preddt) * 100, 2))\n",
    "\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_hund_thou_two_equal, preddt))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.ii.ii. 100,000 (1-star and 5-star) unequal reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 89.38\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.75      0.71      0.73      2207\n",
      "         5.0       0.93      0.94      0.93      8856\n",
      "\n",
      "    accuracy                           0.89     11063\n",
      "   macro avg       0.84      0.83      0.83     11063\n",
      "weighted avg       0.89      0.89      0.89     11063\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_hund_2 = DecisionTreeClassifier()\n",
    "dt_hund_2.fit(x_train_hund_thou_two_unequal, y_train_hund_thou_two_unequal)\n",
    "preddt = dt_hund_2.predict(x_test_hund_thou_two_unequal)\n",
    "\n",
    "print()\n",
    "print(\"Score:\", round(f1_score(y_test_hund_thou_two_unequal, preddt, average='weighted') * 100, 2))\n",
    "\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_hund_thou_two_unequal, preddt))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.iii.i. 100,000 (1-star, 3-star, and 5-star) equal reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 64.3\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.71      0.68      0.69      1640\n",
      "         3.0       0.57      0.56      0.56      1604\n",
      "         5.0       0.65      0.70      0.67      1549\n",
      "\n",
      "    accuracy                           0.64      4793\n",
      "   macro avg       0.64      0.64      0.64      4793\n",
      "weighted avg       0.64      0.64      0.64      4793\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_hund_3 = DecisionTreeClassifier()\n",
    "dt_hund_3.fit(x_train_hund_thou_three_equal, y_train_hund_thou_three_equal)\n",
    "preddt = dt_hund_3.predict(x_test_hund_thou_three_equal)\n",
    "\n",
    "print()\n",
    "print(\"Score:\", round(accuracy_score(y_test_hund_thou_three_equal, preddt) * 100, 2))\n",
    "\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_hund_thou_three_equal, preddt))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.iii.ii. 100,000 (1-star, 3-star, and 5-star) unequal reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 73.76\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.63      0.59      0.61      2231\n",
      "         3.0       0.45      0.40      0.43      2272\n",
      "         5.0       0.83      0.87      0.85      8832\n",
      "\n",
      "    accuracy                           0.74     13335\n",
      "   macro avg       0.64      0.62      0.63     13335\n",
      "weighted avg       0.73      0.74      0.74     13335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_hund_3 = DecisionTreeClassifier()\n",
    "dt_hund_3.fit(x_train_hund_thou_three_unequal, y_train_hund_thou_three_unequal)\n",
    "preddt = dt_hund_3.predict(x_test_hund_thou_three_unequal)\n",
    "\n",
    "print()\n",
    "print(\"Score:\", round(f1_score(y_test_hund_thou_three_unequal, preddt, average='weighted') * 100, 2))\n",
    "\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_hund_thou_three_unequal, preddt))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above models, we can compare the accuracy scores:\n",
    "* Multinomial Naive Bayes:\n",
    "  * Equal \n",
    "\n",
    "|           | 1-5 star | 1 & 5 star | 1, 3, 5 star |\n",
    "|-----------|----------|------------|--------------|\n",
    "| 10,000    | <span style='background:lightcoral'> 47.05  </span>| <span style='background:lightgreen'> 90.52  </span>   | <span style='background:lightgoldenrodyellow'> 74.67 </span> |\n",
    "| 100,000   | <span style='background:lightcoral'> 52.77 </span> | <span style='background:lightgreen'> **94.9** </span> | <span style='background:lightgoldenrodyellow'> 78.24 </span> |\n",
    "| 1,000,000 | <span style='background:lightgoldenrodyellow'> 78.24 </span>     | <span style='background:lightgreen'> 93.54 </span>    | <span style='background:lightgoldenrodyellow'> 79.66 </span> |\n",
    "\n",
    "\n",
    "* Random Forest Classifier:\n",
    "  * Equal \n",
    "\n",
    "|           | 1-5 star | 1 & 5 star | 1, 3, 5 star |\n",
    "|-----------|----------|------------|--------------|\n",
    "| 10,000    | <span style='background:lightcoral'> 41.81 </span> | <span style='background:lightgreen'> 91.18 </span>     | <span style='background:lightgoldenrodyellow'> 70.09 </span> |\n",
    "| 100,000   | <span style='background:lightcoral'> 49.67 </span> | <span style='background:lightgreen'> 93.71 </span>     | <span style='background:lightgoldenrodyellow'> 76.84 </span> |\n",
    "| 1,000,000 | <span style='background:lightgoldenrodyellow'> 77.93 </span>     | <span style='background:lightgreen'> **94.64** </span> | <span style='background:lightgoldenrodyellow'> 79.98 </span> |\n",
    "\n",
    "* Decision Tree Classifier:\n",
    "  * Equal\n",
    "\n",
    "|           | 1-5 star | 1 & 5 star | 1, 3, 5 star |\n",
    "|-----------|----------|------------|--------------|\n",
    "| 10,000    | <span style='background:lightcoral'> 30.14 </span> | <span style='background:lightgoldenrodyellow'> 77.45 </span>         | <span style='background:lightcoral'> 52.62 </span> |\n",
    "| 100,000   | <span style='background:lightcoral'> 37.56 </span> | <span style='background:lightgreen'> 85.67 </span>     | <span style='background:lightgoldenrodyellow'> 63.78 </span>     |\n",
    "| 1,000,000 | <span style='background:lightgoldenrodyellow'> 63.45 </span>     | <span style='background:lightgreen'> **88.18** </span> | <span style='background:lightgoldenrodyellow'> 67.77 </span>     |\n",
    "\n",
    "Since the Multinomial Naive Bayes makes the most accurate prediction, let's use it to predict a sample positive, a sample neutral, and a sample negative review:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Classify a positive review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample positive review:\n",
      "I've taken a lot of spin classes over the years, and nothing compares to the classes at Body Cycle. From the nice, clean space and amazing bikes, to the welcoming and motivating instructors, every class is a top notch work out.\n",
      "\n",
      "For anyone who struggles to fit workouts in, the online scheduling system makes it easy to plan ahead (and there's no need to line up way in advanced like many gyms make you do).\n",
      "\n",
      "There is no way I can write this review without giving Russell, the owner of Body Cycle, a shout out. Russell's passion for fitness and cycling is so evident, as is his desire for all of his clients to succeed. He is always dropping in to classes to check in/provide encouragement, and is open to ideas and recommendations from anyone. Russell always wears a smile on his face, even when he's kicking your butt in class!\n",
      "\n",
      "Actual Rating:  5.0\n",
      "Predicted Rating: 5.0\n"
     ]
    }
   ],
   "source": [
    "pos_rev = yelp_sample_equal_hund_thou['text'][5][1]\n",
    "pos_rev_trans = vocab_hund_thou_two.transform([pos_rev])\n",
    "\n",
    "print()\n",
    "print(\"Sample positive review:\")\n",
    "print(pos_rev)\n",
    "\n",
    "print()\n",
    "print(\"Actual Rating: \", yelp_sample_equal_hund_thou['stars'][5][1])\n",
    "print(\"Predicted Rating:\", mnb_hund_2.predict(pos_rev_trans)[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Classify a negative review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample negative review:\n",
      "I am a long term frequent customer of this establishment. I just went in to order take out (3 apps) and was told they're too busy to do it. Really? The place is maybe half full at best. Does your dick reach your ass? Yes? Go fuck yourself! I'm a frequent customer AND great tipper. Glad that Kanella just opened. NEVER going back to dmitris!\n",
      "\n",
      "Actual Rating:  1.0\n",
      "Predicted Rating: 1.0\n"
     ]
    }
   ],
   "source": [
    "neg_rev = yelp_sample_equal_hund_thou['text'][1][5]\n",
    "neg_rev_trans = vocab_hund_thou_two.transform([neg_rev])\n",
    "\n",
    "print()\n",
    "print(\"Sample negative review:\")\n",
    "print(neg_rev)\n",
    "\n",
    "print()\n",
    "print(\"Actual Rating: \", yelp_sample_equal_hund_thou['stars'][1][5])\n",
    "print(\"Predicted Rating:\", mnb_hund_2.predict(neg_rev_trans)[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
