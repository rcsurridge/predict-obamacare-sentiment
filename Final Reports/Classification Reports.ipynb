{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Sentiment Analysis of Yelp Reviews\n",
    "## Author: Robert Surridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rsurridge/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# IMPORT NECESSARY PACKAGES\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "%matplotlib inline\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multinomial Naive Bayes\n",
      "\n",
      "('all_stars', 'unigram', 'equal') Accuracy Score: 51.38\n",
      "\n",
      "('all_stars', 'unigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.62      0.65      0.64      1626\n",
      "         2.0       0.44      0.43      0.44      1584\n",
      "         3.0       0.43      0.45      0.44      1650\n",
      "         4.0       0.45      0.49      0.47      1596\n",
      "         5.0       0.66      0.54      0.60      1532\n",
      "\n",
      "    accuracy                           0.51      7988\n",
      "   macro avg       0.52      0.51      0.52      7988\n",
      "weighted avg       0.52      0.51      0.52      7988\n",
      "\n",
      "\n",
      "('all_stars', 'unigram', 'unequal') f1_score: 58.44\n",
      "\n",
      "('all_stars', 'unigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.58      0.69      0.63      2168\n",
      "         2.0       0.36      0.22      0.27      1566\n",
      "         3.0       0.38      0.26      0.31      2339\n",
      "         4.0       0.45      0.56      0.50      5026\n",
      "         5.0       0.76      0.74      0.75      8901\n",
      "\n",
      "    accuracy                           0.59     20000\n",
      "   macro avg       0.51      0.49      0.49     20000\n",
      "weighted avg       0.59      0.59      0.58     20000\n",
      "\n",
      "\n",
      "('all_stars', 'bigram', 'equal') Accuracy Score: 49.74\n",
      "\n",
      "('all_stars', 'bigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.67      0.61      0.64      1626\n",
      "         2.0       0.45      0.45      0.45      1584\n",
      "         3.0       0.42      0.45      0.43      1650\n",
      "         4.0       0.41      0.44      0.42      1596\n",
      "         5.0       0.57      0.54      0.55      1532\n",
      "\n",
      "    accuracy                           0.50      7988\n",
      "   macro avg       0.50      0.50      0.50      7988\n",
      "weighted avg       0.50      0.50      0.50      7988\n",
      "\n",
      "\n",
      "('all_stars', 'bigram', 'unequal') f1_score: 54.61\n",
      "\n",
      "('all_stars', 'bigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.64      0.67      0.66      2168\n",
      "         2.0       0.31      0.12      0.18      1566\n",
      "         3.0       0.32      0.16      0.21      2339\n",
      "         4.0       0.40      0.46      0.43      5026\n",
      "         5.0       0.69      0.79      0.74      8901\n",
      "\n",
      "    accuracy                           0.57     20000\n",
      "   macro avg       0.47      0.44      0.44     20000\n",
      "weighted avg       0.54      0.57      0.55     20000\n",
      "\n",
      "\n",
      "('all_stars', 'trigram', 'equal') Accuracy Score: 29.68\n",
      "\n",
      "('all_stars', 'trigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.61      0.24      0.34      1626\n",
      "         2.0       0.42      0.15      0.22      1584\n",
      "         3.0       0.37      0.14      0.21      1650\n",
      "         4.0       0.31      0.22      0.26      1596\n",
      "         5.0       0.23      0.76      0.35      1532\n",
      "\n",
      "    accuracy                           0.30      7988\n",
      "   macro avg       0.39      0.30      0.28      7988\n",
      "weighted avg       0.39      0.30      0.28      7988\n",
      "\n",
      "\n",
      "('all_stars', 'trigram', 'unequal') f1_score: 35.59\n",
      "\n",
      "('all_stars', 'trigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.39      0.38      0.38      2168\n",
      "         2.0       0.11      0.55      0.18      1566\n",
      "         3.0       0.19      0.27      0.22      2339\n",
      "         4.0       0.38      0.20      0.27      5026\n",
      "         5.0       0.74      0.34      0.47      8901\n",
      "\n",
      "    accuracy                           0.32     20000\n",
      "   macro avg       0.36      0.35      0.30     20000\n",
      "weighted avg       0.50      0.32      0.36     20000\n",
      "\n",
      "\n",
      "('1_5_stars', 'unigram', 'equal') Accuracy Score: 94.46\n",
      "\n",
      "('1_5_stars', 'unigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.94      0.95      0.95      1604\n",
      "         5.0       0.95      0.94      0.94      1592\n",
      "\n",
      "    accuracy                           0.94      3196\n",
      "   macro avg       0.94      0.94      0.94      3196\n",
      "weighted avg       0.94      0.94      0.94      3196\n",
      "\n",
      "\n",
      "('1_5_stars', 'unigram', 'unequal') f1_score: 94.57\n",
      "\n",
      "('1_5_stars', 'unigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.84      0.90      0.87      2207\n",
      "         5.0       0.97      0.96      0.97      8856\n",
      "\n",
      "    accuracy                           0.95     11063\n",
      "   macro avg       0.91      0.93      0.92     11063\n",
      "weighted avg       0.95      0.95      0.95     11063\n",
      "\n",
      "\n",
      "('1_5_stars', 'bigram', 'equal') Accuracy Score: 90.08\n",
      "\n",
      "('1_5_stars', 'bigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.96      0.83      0.89      1604\n",
      "         5.0       0.85      0.97      0.91      1592\n",
      "\n",
      "    accuracy                           0.90      3196\n",
      "   macro avg       0.91      0.90      0.90      3196\n",
      "weighted avg       0.91      0.90      0.90      3196\n",
      "\n",
      "\n",
      "('1_5_stars', 'bigram', 'unequal') f1_score: 91.53\n",
      "\n",
      "('1_5_stars', 'bigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.72      0.92      0.81      2207\n",
      "         5.0       0.98      0.91      0.94      8856\n",
      "\n",
      "    accuracy                           0.91     11063\n",
      "   macro avg       0.85      0.91      0.87     11063\n",
      "weighted avg       0.93      0.91      0.92     11063\n",
      "\n",
      "\n",
      "('1_5_stars', 'trigram', 'equal') Accuracy Score: 56.57\n",
      "\n",
      "('1_5_stars', 'trigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.97      0.14      0.24      1604\n",
      "         5.0       0.53      1.00      0.70      1592\n",
      "\n",
      "    accuracy                           0.57      3196\n",
      "   macro avg       0.75      0.57      0.47      3196\n",
      "weighted avg       0.75      0.57      0.47      3196\n",
      "\n",
      "\n",
      "('1_5_stars', 'trigram', 'unequal') f1_score: 42.69\n",
      "\n",
      "('1_5_stars', 'trigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.25      0.99      0.41      2207\n",
      "         5.0       0.99      0.28      0.43      8856\n",
      "\n",
      "    accuracy                           0.42     11063\n",
      "   macro avg       0.62      0.63      0.42     11063\n",
      "weighted avg       0.85      0.42      0.43     11063\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'unigram', 'equal') Accuracy Score: 77.91\n",
      "\n",
      "('1_3_5_stars', 'unigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.83      0.79      0.81      1640\n",
      "         3.0       0.67      0.78      0.72      1604\n",
      "         5.0       0.87      0.76      0.81      1549\n",
      "\n",
      "    accuracy                           0.78      4793\n",
      "   macro avg       0.79      0.78      0.78      4793\n",
      "weighted avg       0.79      0.78      0.78      4793\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'unigram', 'unequal') f1_score: 84.24\n",
      "\n",
      "('1_3_5_stars', 'unigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.75      0.78      0.76      2231\n",
      "         3.0       0.62      0.64      0.63      2272\n",
      "         5.0       0.92      0.91      0.92      8832\n",
      "\n",
      "    accuracy                           0.84     13335\n",
      "   macro avg       0.77      0.78      0.77     13335\n",
      "weighted avg       0.84      0.84      0.84     13335\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'bigram', 'equal') Accuracy Score: 76.01\n",
      "\n",
      "('1_3_5_stars', 'bigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.86      0.75      0.80      1640\n",
      "         3.0       0.69      0.71      0.70      1604\n",
      "         5.0       0.75      0.82      0.78      1549\n",
      "\n",
      "    accuracy                           0.76      4793\n",
      "   macro avg       0.76      0.76      0.76      4793\n",
      "weighted avg       0.77      0.76      0.76      4793\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'bigram', 'unequal') f1_score: 81.84\n",
      "\n",
      "('1_3_5_stars', 'bigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.75      0.78      0.76      2231\n",
      "         3.0       0.56      0.59      0.57      2272\n",
      "         5.0       0.90      0.89      0.90      8832\n",
      "\n",
      "    accuracy                           0.82     13335\n",
      "   macro avg       0.74      0.75      0.74     13335\n",
      "weighted avg       0.82      0.82      0.82     13335\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'trigram', 'equal') Accuracy Score: 42.48\n",
      "\n",
      "('1_3_5_stars', 'trigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.86      0.20      0.33      1640\n",
      "         3.0       0.67      0.13      0.22      1604\n",
      "         5.0       0.36      0.96      0.53      1549\n",
      "\n",
      "    accuracy                           0.42      4793\n",
      "   macro avg       0.63      0.43      0.36      4793\n",
      "weighted avg       0.64      0.42      0.36      4793\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'trigram', 'unequal') f1_score: 41.81\n",
      "\n",
      "('1_3_5_stars', 'trigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.30      0.79      0.44      2231\n",
      "         3.0       0.27      0.59      0.37      2272\n",
      "         5.0       0.94      0.27      0.43      8832\n",
      "\n",
      "    accuracy                           0.41     13335\n",
      "   macro avg       0.50      0.55      0.41     13335\n",
      "weighted avg       0.72      0.41      0.42     13335\n",
      "\n",
      "\n",
      "Decision Tree Classifier\n",
      "\n",
      "('1_5_stars', 'unigram', 'equal') Accuracy Score: 85.95\n",
      "\n",
      "('1_5_stars', 'unigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.87      0.85      0.86      1604\n",
      "         5.0       0.85      0.87      0.86      1592\n",
      "\n",
      "    accuracy                           0.86      3196\n",
      "   macro avg       0.86      0.86      0.86      3196\n",
      "weighted avg       0.86      0.86      0.86      3196\n",
      "\n",
      "\n",
      "('1_5_stars', 'unigram', 'unequal') f1_score: 90.95\n",
      "\n",
      "('1_5_stars', 'unigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.78      0.76      0.77      2207\n",
      "         5.0       0.94      0.95      0.94      8856\n",
      "\n",
      "    accuracy                           0.91     11063\n",
      "   macro avg       0.86      0.85      0.86     11063\n",
      "weighted avg       0.91      0.91      0.91     11063\n",
      "\n",
      "\n",
      "('1_5_stars', 'bigram', 'equal') Accuracy Score: 80.88\n",
      "\n",
      "('1_5_stars', 'bigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.78      0.87      0.82      1604\n",
      "         5.0       0.85      0.75      0.80      1592\n",
      "\n",
      "    accuracy                           0.81      3196\n",
      "   macro avg       0.81      0.81      0.81      3196\n",
      "weighted avg       0.81      0.81      0.81      3196\n",
      "\n",
      "\n",
      "('1_5_stars', 'bigram', 'unequal') f1_score: 84.59\n",
      "\n",
      "('1_5_stars', 'bigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.57      0.74      0.65      2207\n",
      "         5.0       0.93      0.86      0.90      8856\n",
      "\n",
      "    accuracy                           0.84     11063\n",
      "   macro avg       0.75      0.80      0.77     11063\n",
      "weighted avg       0.86      0.84      0.85     11063\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'unigram', 'equal') Accuracy Score: 65.03\n",
      "\n",
      "('1_3_5_stars', 'unigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.72      0.69      0.70      1640\n",
      "         3.0       0.57      0.57      0.57      1604\n",
      "         5.0       0.67      0.70      0.68      1549\n",
      "\n",
      "    accuracy                           0.65      4793\n",
      "   macro avg       0.65      0.65      0.65      4793\n",
      "weighted avg       0.65      0.65      0.65      4793\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'unigram', 'unequal') f1_score: 74.88\n",
      "\n",
      "('1_3_5_stars', 'unigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.65      0.64      0.65      2231\n",
      "         3.0       0.45      0.40      0.42      2272\n",
      "         5.0       0.85      0.87      0.86      8832\n",
      "\n",
      "    accuracy                           0.75     13335\n",
      "   macro avg       0.65      0.64      0.64     13335\n",
      "weighted avg       0.75      0.75      0.75     13335\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'bigram', 'equal') Accuracy Score: 62.22\n",
      "\n",
      "('1_3_5_stars', 'bigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.61      0.75      0.67      1640\n",
      "         3.0       0.60      0.48      0.53      1604\n",
      "         5.0       0.65      0.64      0.64      1549\n",
      "\n",
      "    accuracy                           0.62      4793\n",
      "   macro avg       0.62      0.62      0.62      4793\n",
      "weighted avg       0.62      0.62      0.62      4793\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'bigram', 'unequal') f1_score: 71.3\n",
      "\n",
      "('1_3_5_stars', 'bigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.49      0.65      0.56      2231\n",
      "         3.0       0.50      0.37      0.42      2272\n",
      "         5.0       0.83      0.82      0.83      8832\n",
      "\n",
      "    accuracy                           0.71     13335\n",
      "   macro avg       0.61      0.61      0.60     13335\n",
      "weighted avg       0.72      0.71      0.71     13335\n",
      "\n",
      "\n",
      "('all_stars', 'unigram', 'equal') Accuracy Score: 40.22\n",
      "\n",
      "('all_stars', 'unigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.54      0.54      0.54      1626\n",
      "         2.0       0.33      0.34      0.34      1584\n",
      "         3.0       0.34      0.31      0.32      1650\n",
      "         4.0       0.33      0.32      0.33      1596\n",
      "         5.0       0.46      0.51      0.48      1532\n",
      "\n",
      "    accuracy                           0.40      7988\n",
      "   macro avg       0.40      0.40      0.40      7988\n",
      "weighted avg       0.40      0.40      0.40      7988\n",
      "\n",
      "\n",
      "('all_stars', 'unigram', 'unequal') f1_score: 48.61\n",
      "\n",
      "('all_stars', 'unigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.53      0.53      0.53      2168\n",
      "         2.0       0.23      0.20      0.21      1566\n",
      "         3.0       0.27      0.23      0.25      2339\n",
      "         4.0       0.36      0.36      0.36      5026\n",
      "         5.0       0.64      0.68      0.66      8901\n",
      "\n",
      "    accuracy                           0.49     20000\n",
      "   macro avg       0.40      0.40      0.40     20000\n",
      "weighted avg       0.48      0.49      0.49     20000\n",
      "\n",
      "\n",
      "('all_stars', 'bigram', 'equal') Accuracy Score: 37.21\n",
      "\n",
      "('all_stars', 'bigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.42      0.59      0.49      1626\n",
      "         2.0       0.33      0.27      0.30      1584\n",
      "         3.0       0.33      0.26      0.29      1650\n",
      "         4.0       0.32      0.31      0.32      1596\n",
      "         5.0       0.42      0.43      0.43      1532\n",
      "\n",
      "    accuracy                           0.37      7988\n",
      "   macro avg       0.36      0.37      0.36      7988\n",
      "weighted avg       0.36      0.37      0.36      7988\n",
      "\n",
      "\n",
      "('all_stars', 'bigram', 'unequal') f1_score: 46.43\n",
      "\n",
      "('all_stars', 'bigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.47      0.46      0.47      2168\n",
      "         2.0       0.25      0.16      0.19      1566\n",
      "         3.0       0.28      0.16      0.20      2339\n",
      "         4.0       0.33      0.36      0.34      5026\n",
      "         5.0       0.61      0.69      0.65      8901\n",
      "\n",
      "    accuracy                           0.48     20000\n",
      "   macro avg       0.39      0.37      0.37     20000\n",
      "weighted avg       0.46      0.48      0.46     20000\n",
      "\n",
      "\n",
      "('1_5_stars', 'trigram', 'equal') Accuracy Score: 62.64\n",
      "\n",
      "('1_5_stars', 'trigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.58      0.95      0.72      1604\n",
      "         5.0       0.85      0.30      0.45      1592\n",
      "\n",
      "    accuracy                           0.63      3196\n",
      "   macro avg       0.72      0.63      0.58      3196\n",
      "weighted avg       0.72      0.63      0.58      3196\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'trigram', 'equal') Accuracy Score: 46.9\n",
      "\n",
      "('1_3_5_stars', 'trigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.41      0.90      0.57      1640\n",
      "         3.0       0.61      0.23      0.34      1604\n",
      "         5.0       0.65      0.25      0.36      1549\n",
      "\n",
      "    accuracy                           0.47      4793\n",
      "   macro avg       0.56      0.46      0.42      4793\n",
      "weighted avg       0.56      0.47      0.42      4793\n",
      "\n",
      "\n",
      "Random Forest Classifier\n",
      "\n",
      "('1_5_stars', 'unigram', 'equal') Accuracy Score: 94.06\n",
      "\n",
      "('1_5_stars', 'unigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.92      0.96      0.94      1604\n",
      "         5.0       0.96      0.92      0.94      1592\n",
      "\n",
      "    accuracy                           0.94      3196\n",
      "   macro avg       0.94      0.94      0.94      3196\n",
      "weighted avg       0.94      0.94      0.94      3196\n",
      "\n",
      "\n",
      "('1_5_stars', 'unigram', 'unequal') f1_score: 94.07\n",
      "\n",
      "('1_5_stars', 'unigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.97      0.74      0.84      2207\n",
      "         5.0       0.94      1.00      0.97      8856\n",
      "\n",
      "    accuracy                           0.94     11063\n",
      "   macro avg       0.96      0.87      0.90     11063\n",
      "weighted avg       0.95      0.94      0.94     11063\n",
      "\n",
      "\n",
      "('1_5_stars', 'bigram', 'equal') Accuracy Score: 86.76\n",
      "\n",
      "('1_5_stars', 'bigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.84      0.91      0.87      1604\n",
      "         5.0       0.90      0.83      0.86      1592\n",
      "\n",
      "    accuracy                           0.87      3196\n",
      "   macro avg       0.87      0.87      0.87      3196\n",
      "weighted avg       0.87      0.87      0.87      3196\n",
      "\n",
      "\n",
      "('1_5_stars', 'bigram', 'unequal') f1_score: 89.9\n",
      "\n",
      "('1_5_stars', 'bigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.76      0.72      0.74      2207\n",
      "         5.0       0.93      0.94      0.94      8856\n",
      "\n",
      "    accuracy                           0.90     11063\n",
      "   macro avg       0.85      0.83      0.84     11063\n",
      "weighted avg       0.90      0.90      0.90     11063\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'unigram', 'equal') Accuracy Score: 78.26\n",
      "\n",
      "('1_3_5_stars', 'unigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.80      0.86      0.83      1640\n",
      "         3.0       0.74      0.67      0.71      1604\n",
      "         5.0       0.80      0.82      0.81      1549\n",
      "\n",
      "    accuracy                           0.78      4793\n",
      "   macro avg       0.78      0.78      0.78      4793\n",
      "weighted avg       0.78      0.78      0.78      4793\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'unigram', 'unequal') f1_score: 77.01\n",
      "\n",
      "('1_3_5_stars', 'unigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.87      0.69      0.77      2231\n",
      "         3.0       0.84      0.21      0.34      2272\n",
      "         5.0       0.80      0.99      0.88      8832\n",
      "\n",
      "    accuracy                           0.81     13335\n",
      "   macro avg       0.83      0.63      0.66     13335\n",
      "weighted avg       0.81      0.81      0.77     13335\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'bigram', 'equal') Accuracy Score: 67.7\n",
      "\n",
      "('1_3_5_stars', 'bigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.63      0.87      0.73      1640\n",
      "         3.0       0.77      0.43      0.55      1604\n",
      "         5.0       0.69      0.73      0.71      1549\n",
      "\n",
      "    accuracy                           0.68      4793\n",
      "   macro avg       0.70      0.68      0.66      4793\n",
      "weighted avg       0.70      0.68      0.66      4793\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'bigram', 'unequal') f1_score: 74.86\n",
      "\n",
      "('1_3_5_stars', 'bigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.67      0.69      0.68      2231\n",
      "         3.0       0.75      0.23      0.35      2272\n",
      "         5.0       0.81      0.94      0.87      8832\n",
      "\n",
      "    accuracy                           0.78     13335\n",
      "   macro avg       0.74      0.62      0.63     13335\n",
      "weighted avg       0.77      0.78      0.75     13335\n",
      "\n",
      "\n",
      "('all_stars', 'unigram', 'equal') Accuracy Score: 50.68\n",
      "\n",
      "('all_stars', 'unigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.56      0.79      0.65      1626\n",
      "         2.0       0.46      0.35      0.40      1584\n",
      "         3.0       0.45      0.37      0.41      1650\n",
      "         4.0       0.45      0.34      0.39      1596\n",
      "         5.0       0.55      0.70      0.61      1532\n",
      "\n",
      "    accuracy                           0.51      7988\n",
      "   macro avg       0.49      0.51      0.49      7988\n",
      "weighted avg       0.49      0.51      0.49      7988\n",
      "\n",
      "\n",
      "('all_stars', 'unigram', 'unequal') f1_score: 48.39\n",
      "\n",
      "('all_stars', 'unigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.66      0.66      0.66      2168\n",
      "         2.0       0.37      0.03      0.06      1566\n",
      "         3.0       0.43      0.07      0.12      2339\n",
      "         4.0       0.40      0.24      0.30      5026\n",
      "         5.0       0.58      0.93      0.72      8901\n",
      "\n",
      "    accuracy                           0.56     20000\n",
      "   macro avg       0.49      0.39      0.37     20000\n",
      "weighted avg       0.51      0.56      0.48     20000\n",
      "\n",
      "\n",
      "('all_stars', 'bigram', 'equal') Accuracy Score: 42.13\n",
      "\n",
      "('all_stars', 'bigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.40      0.83      0.54      1626\n",
      "         2.0       0.43      0.18      0.26      1584\n",
      "         3.0       0.46      0.23      0.31      1650\n",
      "         4.0       0.40      0.26      0.31      1596\n",
      "         5.0       0.45      0.60      0.51      1532\n",
      "\n",
      "    accuracy                           0.42      7988\n",
      "   macro avg       0.43      0.42      0.39      7988\n",
      "weighted avg       0.43      0.42      0.39      7988\n",
      "\n",
      "\n",
      "('all_stars', 'bigram', 'unequal') f1_score: 47.31\n",
      "\n",
      "('all_stars', 'bigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.59      0.56      0.57      2168\n",
      "         2.0       0.36      0.06      0.11      1566\n",
      "         3.0       0.48      0.09      0.15      2339\n",
      "         4.0       0.34      0.27      0.30      5026\n",
      "         5.0       0.58      0.87      0.70      8901\n",
      "\n",
      "    accuracy                           0.53     20000\n",
      "   macro avg       0.47      0.37      0.36     20000\n",
      "weighted avg       0.49      0.53      0.47     20000\n",
      "\n",
      "\n",
      "('1_5_stars', 'trigram', 'equal') Accuracy Score: 62.33\n",
      "\n",
      "('1_5_stars', 'trigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.57      0.97      0.72      1604\n",
      "         5.0       0.90      0.27      0.42      1592\n",
      "\n",
      "    accuracy                           0.62      3196\n",
      "   macro avg       0.74      0.62      0.57      3196\n",
      "weighted avg       0.74      0.62      0.57      3196\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'trigram', 'equal') Accuracy Score: 46.17\n",
      "\n",
      "('1_3_5_stars', 'trigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.41      0.94      0.57      1640\n",
      "         3.0       0.70      0.15      0.25      1604\n",
      "         5.0       0.66      0.28      0.39      1549\n",
      "\n",
      "    accuracy                           0.46      4793\n",
      "   macro avg       0.59      0.46      0.40      4793\n",
      "weighted avg       0.59      0.46      0.40      4793\n",
      "\n",
      "\n",
      "Logistic Regression: 100 Iterations\n",
      "\n",
      "('1_5_stars', 'unigram', 'equal') Accuracy Score: 95.28\n",
      "\n",
      "('1_5_stars', 'unigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.95      0.95      0.95      1604\n",
      "         5.0       0.95      0.95      0.95      1592\n",
      "\n",
      "    accuracy                           0.95      3196\n",
      "   macro avg       0.95      0.95      0.95      3196\n",
      "weighted avg       0.95      0.95      0.95      3196\n",
      "\n",
      "\n",
      "('1_5_stars', 'unigram', 'unequal') f1_score: 97.0\n",
      "\n",
      "('1_5_stars', 'unigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.94      0.91      0.92      2207\n",
      "         5.0       0.98      0.99      0.98      8856\n",
      "\n",
      "    accuracy                           0.97     11063\n",
      "   macro avg       0.96      0.95      0.95     11063\n",
      "weighted avg       0.97      0.97      0.97     11063\n",
      "\n",
      "\n",
      "('1_5_stars', 'bigram', 'equal') Accuracy Score: 90.24\n",
      "\n",
      "('1_5_stars', 'bigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.93      0.88      0.90      1604\n",
      "         5.0       0.88      0.93      0.90      1592\n",
      "\n",
      "    accuracy                           0.90      3196\n",
      "   macro avg       0.90      0.90      0.90      3196\n",
      "weighted avg       0.90      0.90      0.90      3196\n",
      "\n",
      "\n",
      "('1_5_stars', 'bigram', 'unequal') f1_score: 90.99\n",
      "\n",
      "('1_5_stars', 'bigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.95      0.62      0.75      2207\n",
      "         5.0       0.91      0.99      0.95      8856\n",
      "\n",
      "    accuracy                           0.92     11063\n",
      "   macro avg       0.93      0.80      0.85     11063\n",
      "weighted avg       0.92      0.92      0.91     11063\n",
      "\n",
      "\n",
      "('1_5_stars', 'trigram', 'equal') Accuracy Score: 63.17\n",
      "\n",
      "('1_5_stars', 'trigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.97      0.28      0.43      1604\n",
      "         5.0       0.58      0.99      0.73      1592\n",
      "\n",
      "    accuracy                           0.63      3196\n",
      "   macro avg       0.77      0.63      0.58      3196\n",
      "weighted avg       0.77      0.63      0.58      3196\n",
      "\n",
      "\n",
      "('1_5_stars', 'trigram', 'unequal') f1_score: 74.3\n",
      "\n",
      "('1_5_stars', 'trigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.96      0.07      0.13      2207\n",
      "         5.0       0.81      1.00      0.90      8856\n",
      "\n",
      "    accuracy                           0.81     11063\n",
      "   macro avg       0.89      0.53      0.51     11063\n",
      "weighted avg       0.84      0.81      0.74     11063\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'unigram', 'equal') Accuracy Score: 80.03\n",
      "\n",
      "('1_3_5_stars', 'unigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.84      0.83      0.83      1640\n",
      "         3.0       0.74      0.72      0.73      1604\n",
      "         5.0       0.82      0.85      0.84      1549\n",
      "\n",
      "    accuracy                           0.80      4793\n",
      "   macro avg       0.80      0.80      0.80      4793\n",
      "weighted avg       0.80      0.80      0.80      4793\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'unigram', 'unequal') f1_score: 86.47\n",
      "\n",
      "('1_3_5_stars', 'unigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.84      0.82      0.83      2231\n",
      "         3.0       0.68      0.61      0.65      2272\n",
      "         5.0       0.92      0.94      0.93      8832\n",
      "\n",
      "    accuracy                           0.87     13335\n",
      "   macro avg       0.81      0.79      0.80     13335\n",
      "weighted avg       0.86      0.87      0.86     13335\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'bigram', 'equal') Accuracy Score: 74.19\n",
      "\n",
      "('1_3_5_stars', 'bigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.79      0.79      0.79      1640\n",
      "         3.0       0.73      0.61      0.66      1604\n",
      "         5.0       0.71      0.83      0.76      1549\n",
      "\n",
      "    accuracy                           0.74      4793\n",
      "   macro avg       0.74      0.74      0.74      4793\n",
      "weighted avg       0.74      0.74      0.74      4793\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'bigram', 'unequal') f1_score: 79.88\n",
      "\n",
      "('1_3_5_stars', 'bigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.85      0.61      0.71      2231\n",
      "         3.0       0.74      0.41      0.53      2272\n",
      "         5.0       0.82      0.98      0.89      8832\n",
      "\n",
      "    accuracy                           0.82     13335\n",
      "   macro avg       0.80      0.66      0.71     13335\n",
      "weighted avg       0.81      0.82      0.80     13335\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'trigram', 'equal') Accuracy Score: 46.65\n",
      "\n",
      "('1_3_5_stars', 'trigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.81      0.28      0.42      1640\n",
      "         3.0       0.70      0.18      0.29      1604\n",
      "         5.0       0.39      0.96      0.55      1549\n",
      "\n",
      "    accuracy                           0.47      4793\n",
      "   macro avg       0.63      0.47      0.42      4793\n",
      "weighted avg       0.64      0.47      0.42      4793\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'trigram', 'unequal') f1_score: 57.22\n",
      "\n",
      "('1_3_5_stars', 'trigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.87      0.09      0.16      2231\n",
      "         3.0       0.74      0.03      0.06      2272\n",
      "         5.0       0.68      1.00      0.81      8832\n",
      "\n",
      "    accuracy                           0.68     13335\n",
      "   macro avg       0.76      0.37      0.34     13335\n",
      "weighted avg       0.72      0.68      0.57     13335\n",
      "\n",
      "\n",
      "('all_stars', 'unigram', 'equal') Accuracy Score: 51.11\n",
      "\n",
      "('all_stars', 'unigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.65      0.67      0.66      1626\n",
      "         2.0       0.43      0.42      0.43      1584\n",
      "         3.0       0.44      0.41      0.42      1650\n",
      "         4.0       0.43      0.42      0.42      1596\n",
      "         5.0       0.59      0.64      0.61      1532\n",
      "\n",
      "    accuracy                           0.51      7988\n",
      "   macro avg       0.51      0.51      0.51      7988\n",
      "weighted avg       0.51      0.51      0.51      7988\n",
      "\n",
      "\n",
      "('all_stars', 'bigram', 'equal') Accuracy Score: 48.8\n",
      "\n",
      "('all_stars', 'bigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.60      0.68      0.64      1626\n",
      "         2.0       0.45      0.37      0.40      1584\n",
      "         3.0       0.44      0.36      0.40      1650\n",
      "         4.0       0.41      0.39      0.40      1596\n",
      "         5.0       0.49      0.65      0.56      1532\n",
      "\n",
      "    accuracy                           0.49      7988\n",
      "   macro avg       0.48      0.49      0.48      7988\n",
      "weighted avg       0.48      0.49      0.48      7988\n",
      "\n",
      "\n",
      "('all_stars', 'unigram', 'unequal') f1_score: 59.54\n",
      "\n",
      "('all_stars', 'unigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.67      0.69      0.68      2168\n",
      "         2.0       0.37      0.34      0.36      1566\n",
      "         3.0       0.39      0.32      0.36      2339\n",
      "         4.0       0.47      0.43      0.45      5026\n",
      "         5.0       0.72      0.81      0.76      8901\n",
      "\n",
      "    accuracy                           0.60     20000\n",
      "   macro avg       0.53      0.52      0.52     20000\n",
      "weighted avg       0.59      0.60      0.60     20000\n",
      "\n",
      "\n",
      "Logistic Regression: 1000 Iterations\n",
      "\n",
      "('1_5_stars', 'unigram', 'equal') Accuracy Score: 95.28\n",
      "\n",
      "('1_5_stars', 'unigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.95      0.95      0.95      1604\n",
      "         5.0       0.95      0.95      0.95      1592\n",
      "\n",
      "    accuracy                           0.95      3196\n",
      "   macro avg       0.95      0.95      0.95      3196\n",
      "weighted avg       0.95      0.95      0.95      3196\n",
      "\n",
      "\n",
      "('1_5_stars', 'unigram', 'unequal') f1_score: 97.0\n",
      "\n",
      "('1_5_stars', 'unigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.94      0.91      0.92      2207\n",
      "         5.0       0.98      0.99      0.98      8856\n",
      "\n",
      "    accuracy                           0.97     11063\n",
      "   macro avg       0.96      0.95      0.95     11063\n",
      "weighted avg       0.97      0.97      0.97     11063\n",
      "\n",
      "\n",
      "('1_5_stars', 'bigram', 'equal') Accuracy Score: 90.24\n",
      "\n",
      "('1_5_stars', 'bigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.93      0.88      0.90      1604\n",
      "         5.0       0.88      0.93      0.90      1592\n",
      "\n",
      "    accuracy                           0.90      3196\n",
      "   macro avg       0.90      0.90      0.90      3196\n",
      "weighted avg       0.90      0.90      0.90      3196\n",
      "\n",
      "\n",
      "('1_5_stars', 'bigram', 'unequal') f1_score: 90.99\n",
      "\n",
      "('1_5_stars', 'bigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.95      0.62      0.75      2207\n",
      "         5.0       0.91      0.99      0.95      8856\n",
      "\n",
      "    accuracy                           0.92     11063\n",
      "   macro avg       0.93      0.80      0.85     11063\n",
      "weighted avg       0.92      0.92      0.91     11063\n",
      "\n",
      "\n",
      "('1_5_stars', 'trigram', 'equal') Accuracy Score: 63.17\n",
      "\n",
      "('1_5_stars', 'trigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.97      0.28      0.43      1604\n",
      "         5.0       0.58      0.99      0.73      1592\n",
      "\n",
      "    accuracy                           0.63      3196\n",
      "   macro avg       0.77      0.63      0.58      3196\n",
      "weighted avg       0.77      0.63      0.58      3196\n",
      "\n",
      "\n",
      "('1_5_stars', 'trigram', 'unequal') f1_score: 74.3\n",
      "\n",
      "('1_5_stars', 'trigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.96      0.07      0.13      2207\n",
      "         5.0       0.81      1.00      0.90      8856\n",
      "\n",
      "    accuracy                           0.81     11063\n",
      "   macro avg       0.89      0.53      0.51     11063\n",
      "weighted avg       0.84      0.81      0.74     11063\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'unigram', 'equal') Accuracy Score: 80.03\n",
      "\n",
      "('1_3_5_stars', 'unigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.84      0.83      0.83      1640\n",
      "         3.0       0.74      0.72      0.73      1604\n",
      "         5.0       0.82      0.85      0.84      1549\n",
      "\n",
      "    accuracy                           0.80      4793\n",
      "   macro avg       0.80      0.80      0.80      4793\n",
      "weighted avg       0.80      0.80      0.80      4793\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'unigram', 'unequal') f1_score: 86.4\n",
      "\n",
      "('1_3_5_stars', 'unigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.84      0.82      0.83      2231\n",
      "         3.0       0.68      0.61      0.65      2272\n",
      "         5.0       0.91      0.94      0.93      8832\n",
      "\n",
      "    accuracy                           0.87     13335\n",
      "   macro avg       0.81      0.79      0.80     13335\n",
      "weighted avg       0.86      0.87      0.86     13335\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'bigram', 'equal') Accuracy Score: 74.19\n",
      "\n",
      "('1_3_5_stars', 'bigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.79      0.79      0.79      1640\n",
      "         3.0       0.73      0.61      0.66      1604\n",
      "         5.0       0.71      0.83      0.76      1549\n",
      "\n",
      "    accuracy                           0.74      4793\n",
      "   macro avg       0.74      0.74      0.74      4793\n",
      "weighted avg       0.74      0.74      0.74      4793\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'bigram', 'unequal') f1_score: 79.86\n",
      "\n",
      "('1_3_5_stars', 'bigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.84      0.61      0.71      2231\n",
      "         3.0       0.74      0.41      0.53      2272\n",
      "         5.0       0.82      0.97      0.89      8832\n",
      "\n",
      "    accuracy                           0.82     13335\n",
      "   macro avg       0.80      0.66      0.71     13335\n",
      "weighted avg       0.81      0.82      0.80     13335\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'trigram', 'equal') Accuracy Score: 46.65\n",
      "\n",
      "('1_3_5_stars', 'trigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.81      0.28      0.42      1640\n",
      "         3.0       0.70      0.18      0.29      1604\n",
      "         5.0       0.39      0.96      0.55      1549\n",
      "\n",
      "    accuracy                           0.47      4793\n",
      "   macro avg       0.63      0.47      0.42      4793\n",
      "weighted avg       0.64      0.47      0.42      4793\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'trigram', 'unequal') f1_score: 57.22\n",
      "\n",
      "('1_3_5_stars', 'trigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.87      0.09      0.16      2231\n",
      "         3.0       0.74      0.03      0.06      2272\n",
      "         5.0       0.68      1.00      0.81      8832\n",
      "\n",
      "    accuracy                           0.68     13335\n",
      "   macro avg       0.76      0.37      0.34     13335\n",
      "weighted avg       0.72      0.68      0.57     13335\n",
      "\n",
      "\n",
      "('all_stars', 'unigram', 'equal') Accuracy Score: 51.19\n",
      "\n",
      "('all_stars', 'unigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.65      0.67      0.66      1626\n",
      "         2.0       0.44      0.43      0.43      1584\n",
      "         3.0       0.44      0.41      0.42      1650\n",
      "         4.0       0.43      0.42      0.42      1596\n",
      "         5.0       0.58      0.64      0.61      1532\n",
      "\n",
      "    accuracy                           0.51      7988\n",
      "   macro avg       0.51      0.51      0.51      7988\n",
      "weighted avg       0.51      0.51      0.51      7988\n",
      "\n",
      "\n",
      "('all_stars', 'bigram', 'equal') Accuracy Score: 48.8\n",
      "\n",
      "('all_stars', 'bigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.60      0.68      0.64      1626\n",
      "         2.0       0.45      0.37      0.41      1584\n",
      "         3.0       0.44      0.36      0.40      1650\n",
      "         4.0       0.41      0.39      0.40      1596\n",
      "         5.0       0.49      0.65      0.56      1532\n",
      "\n",
      "    accuracy                           0.49      7988\n",
      "   macro avg       0.48      0.49      0.48      7988\n",
      "weighted avg       0.48      0.49      0.48      7988\n",
      "\n",
      "\n",
      "('all_stars', 'unigram', 'unequal') f1_score: 59.5\n",
      "\n",
      "('all_stars', 'unigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.66      0.69      0.68      2168\n",
      "         2.0       0.37      0.33      0.35      1566\n",
      "         3.0       0.39      0.33      0.36      2339\n",
      "         4.0       0.47      0.42      0.44      5026\n",
      "         5.0       0.73      0.81      0.77      8901\n",
      "\n",
      "    accuracy                           0.60     20000\n",
      "   macro avg       0.53      0.52      0.52     20000\n",
      "weighted avg       0.59      0.60      0.60     20000\n",
      "\n",
      "\n",
      "Logistic Regression: 10000 Iterations\n",
      "\n",
      "('1_5_stars', 'unigram', 'equal') Accuracy Score: 95.28\n",
      "\n",
      "('1_5_stars', 'unigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.95      0.95      0.95      1604\n",
      "         5.0       0.95      0.95      0.95      1592\n",
      "\n",
      "    accuracy                           0.95      3196\n",
      "   macro avg       0.95      0.95      0.95      3196\n",
      "weighted avg       0.95      0.95      0.95      3196\n",
      "\n",
      "\n",
      "('1_5_stars', 'unigram', 'unequal') f1_score: 97.0\n",
      "\n",
      "('1_5_stars', 'unigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.94      0.91      0.92      2207\n",
      "         5.0       0.98      0.99      0.98      8856\n",
      "\n",
      "    accuracy                           0.97     11063\n",
      "   macro avg       0.96      0.95      0.95     11063\n",
      "weighted avg       0.97      0.97      0.97     11063\n",
      "\n",
      "\n",
      "('1_5_stars', 'bigram', 'equal') Accuracy Score: 90.24\n",
      "\n",
      "('1_5_stars', 'bigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.93      0.88      0.90      1604\n",
      "         5.0       0.88      0.93      0.90      1592\n",
      "\n",
      "    accuracy                           0.90      3196\n",
      "   macro avg       0.90      0.90      0.90      3196\n",
      "weighted avg       0.90      0.90      0.90      3196\n",
      "\n",
      "\n",
      "('1_5_stars', 'bigram', 'unequal') f1_score: 90.99\n",
      "\n",
      "('1_5_stars', 'bigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.95      0.62      0.75      2207\n",
      "         5.0       0.91      0.99      0.95      8856\n",
      "\n",
      "    accuracy                           0.92     11063\n",
      "   macro avg       0.93      0.80      0.85     11063\n",
      "weighted avg       0.92      0.92      0.91     11063\n",
      "\n",
      "\n",
      "('1_5_stars', 'trigram', 'equal') Accuracy Score: 63.17\n",
      "\n",
      "('1_5_stars', 'trigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.97      0.28      0.43      1604\n",
      "         5.0       0.58      0.99      0.73      1592\n",
      "\n",
      "    accuracy                           0.63      3196\n",
      "   macro avg       0.77      0.63      0.58      3196\n",
      "weighted avg       0.77      0.63      0.58      3196\n",
      "\n",
      "\n",
      "('1_5_stars', 'trigram', 'unequal') f1_score: 74.3\n",
      "\n",
      "('1_5_stars', 'trigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.96      0.07      0.13      2207\n",
      "         5.0       0.81      1.00      0.90      8856\n",
      "\n",
      "    accuracy                           0.81     11063\n",
      "   macro avg       0.89      0.53      0.51     11063\n",
      "weighted avg       0.84      0.81      0.74     11063\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'unigram', 'equal') Accuracy Score: 80.03\n",
      "\n",
      "('1_3_5_stars', 'unigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.84      0.83      0.83      1640\n",
      "         3.0       0.74      0.72      0.73      1604\n",
      "         5.0       0.82      0.85      0.84      1549\n",
      "\n",
      "    accuracy                           0.80      4793\n",
      "   macro avg       0.80      0.80      0.80      4793\n",
      "weighted avg       0.80      0.80      0.80      4793\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'unigram', 'unequal') f1_score: 86.4\n",
      "\n",
      "('1_3_5_stars', 'unigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.84      0.82      0.83      2231\n",
      "         3.0       0.68      0.61      0.65      2272\n",
      "         5.0       0.91      0.94      0.93      8832\n",
      "\n",
      "    accuracy                           0.87     13335\n",
      "   macro avg       0.81      0.79      0.80     13335\n",
      "weighted avg       0.86      0.87      0.86     13335\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'bigram', 'equal') Accuracy Score: 74.19\n",
      "\n",
      "('1_3_5_stars', 'bigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.79      0.79      0.79      1640\n",
      "         3.0       0.73      0.61      0.66      1604\n",
      "         5.0       0.71      0.83      0.76      1549\n",
      "\n",
      "    accuracy                           0.74      4793\n",
      "   macro avg       0.74      0.74      0.74      4793\n",
      "weighted avg       0.74      0.74      0.74      4793\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'bigram', 'unequal') f1_score: 79.86\n",
      "\n",
      "('1_3_5_stars', 'bigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.84      0.61      0.71      2231\n",
      "         3.0       0.74      0.41      0.53      2272\n",
      "         5.0       0.82      0.97      0.89      8832\n",
      "\n",
      "    accuracy                           0.82     13335\n",
      "   macro avg       0.80      0.66      0.71     13335\n",
      "weighted avg       0.81      0.82      0.80     13335\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'trigram', 'equal') Accuracy Score: 46.65\n",
      "\n",
      "('1_3_5_stars', 'trigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.81      0.28      0.42      1640\n",
      "         3.0       0.70      0.18      0.29      1604\n",
      "         5.0       0.39      0.96      0.55      1549\n",
      "\n",
      "    accuracy                           0.47      4793\n",
      "   macro avg       0.63      0.47      0.42      4793\n",
      "weighted avg       0.64      0.47      0.42      4793\n",
      "\n",
      "\n",
      "('1_3_5_stars', 'trigram', 'unequal') f1_score: 57.22\n",
      "\n",
      "('1_3_5_stars', 'trigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.87      0.09      0.16      2231\n",
      "         3.0       0.74      0.03      0.06      2272\n",
      "         5.0       0.68      1.00      0.81      8832\n",
      "\n",
      "    accuracy                           0.68     13335\n",
      "   macro avg       0.76      0.37      0.34     13335\n",
      "weighted avg       0.72      0.68      0.57     13335\n",
      "\n",
      "\n",
      "('all_stars', 'unigram', 'equal') Accuracy Score: 51.19\n",
      "\n",
      "('all_stars', 'unigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.65      0.67      0.66      1626\n",
      "         2.0       0.44      0.43      0.43      1584\n",
      "         3.0       0.44      0.41      0.42      1650\n",
      "         4.0       0.43      0.42      0.42      1596\n",
      "         5.0       0.58      0.64      0.61      1532\n",
      "\n",
      "    accuracy                           0.51      7988\n",
      "   macro avg       0.51      0.51      0.51      7988\n",
      "weighted avg       0.51      0.51      0.51      7988\n",
      "\n",
      "\n",
      "('all_stars', 'bigram', 'equal') Accuracy Score: 48.8\n",
      "\n",
      "('all_stars', 'bigram', 'equal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.60      0.68      0.64      1626\n",
      "         2.0       0.45      0.37      0.41      1584\n",
      "         3.0       0.44      0.36      0.40      1650\n",
      "         4.0       0.41      0.39      0.40      1596\n",
      "         5.0       0.49      0.65      0.56      1532\n",
      "\n",
      "    accuracy                           0.49      7988\n",
      "   macro avg       0.48      0.49      0.48      7988\n",
      "weighted avg       0.48      0.49      0.48      7988\n",
      "\n",
      "\n",
      "('all_stars', 'unigram', 'unequal') f1_score: 59.5\n",
      "\n",
      "('all_stars', 'unigram', 'unequal') Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.66      0.69      0.68      2168\n",
      "         2.0       0.37      0.33      0.35      1566\n",
      "         3.0       0.39      0.33      0.36      2339\n",
      "         4.0       0.47      0.42      0.44      5026\n",
      "         5.0       0.73      0.81      0.77      8901\n",
      "\n",
      "    accuracy                           0.60     20000\n",
      "   macro avg       0.53      0.52      0.52     20000\n",
      "weighted avg       0.59      0.60      0.60     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LOAD AND MODEL YELP DATA TO PRINT OUT MACHINE LEARNING CLASSIFICATION REPORTS\n",
    "\n",
    "yelp_data = pd.read_json('..Downloads/yelp_data/yelp_academic_dataset_review.json', \n",
    "                         lines=True, chunksize=100_000)\n",
    "for chunk in yelp_data:\n",
    "    yelp_sample_unequal = chunk\n",
    "    result = chunk.to_json(orient=\"records\")\n",
    "    with open(\"yelp_sample.json\", \"w\") as f:\n",
    "        json.dump(result, f)\n",
    "    break\n",
    "\n",
    "yelp_sample_unequal['stars'] = yelp_sample_unequal['stars'].astype(float)\n",
    "\n",
    "unigram_vocab = (CountVectorizer(ngram_range=(1, 1), stop_words='english')\n",
    "                 .fit(yelp_sample_unequal.loc[:, 'text']))\n",
    "\n",
    "bigram_vocab = (CountVectorizer(ngram_range=(2, 2), stop_words='english')\n",
    "                .fit(yelp_sample_unequal.loc[:, 'text']))\n",
    "\n",
    "trigram_vocab = (CountVectorizer(ngram_range=(3, 3), stop_words='english')\n",
    "                .fit(yelp_sample_unequal.loc[:, 'text']))\n",
    "\n",
    "yelp_classify = yelp_sample_unequal.loc[:, ['stars', 'text']]\n",
    "\n",
    "x_unequal = yelp_classify['text']\n",
    "y_unequal = yelp_classify['stars']\n",
    "\n",
    "unequal_count = y_unequal.value_counts()\n",
    "min_count = unequal_count.min()\n",
    "yelp_sample_equal = (yelp_sample_unequal.groupby('stars').apply(lambda x: x[:min_count]))\n",
    "equal_count = yelp_sample_equal['stars'].value_counts()\n",
    "\n",
    "x_equal = yelp_sample_equal['text']\n",
    "y_equal = yelp_sample_equal['stars']\n",
    "\n",
    "combo = list(product(('all_stars', '1_5_stars', '1_3_5_stars'), \n",
    "                     ('unigram', 'bigram', 'trigram'), \n",
    "                     ('equal','unequal')))\n",
    "\n",
    "new_combo = list(product(('1_5_stars', '1_3_5_stars'), \n",
    "                         ('unigram', 'bigram', 'trigram'), \n",
    "                         ('equal','unequal')))\n",
    "new_combo = (new_combo + [('all_stars','unigram', 'equal')] \n",
    "                       + [('all_stars','bigram', 'equal')] \n",
    "                       + [('all_stars','unigram', 'unequal')])\n",
    "\n",
    "brand_new_combo = list(product(('1_5_stars', '1_3_5_stars', 'all_stars'),\n",
    "                               ('unigram', 'bigram'), \n",
    "                               ('equal', 'unequal')))\n",
    "brand_new_combo = (brand_new_combo + [('1_5_stars', 'trigram', 'equal')] \n",
    "                                   + [('1_3_5_stars', 'trigram', 'equal')])\n",
    "\n",
    "def star_df(star, df):\n",
    "    \"\"\"\n",
    "    This function takes in a string of star classification and subsets the \n",
    "    rows of the data for the corressponding stars\n",
    "    \"\"\"\n",
    "    \n",
    "    if 'all_stars' == star:\n",
    "        return  df\n",
    "    elif '1_5_stars' == star:\n",
    "        return df[(df['stars']==1) | (df['stars']==5)]\n",
    "    else:\n",
    "        return df[(df['stars']==1) | (df['stars']==3) | (df['stars']==5)]\n",
    "    \n",
    "def n_gram_df(str, df):\n",
    "    \"\"\"\n",
    "    This function takes in a string for the corresponding n-gram and the \n",
    "    subsetted star data frame. Then creates the ngram and then creates a \n",
    "    Spacy Sparce data matrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    x_df = df['text']\n",
    "    if str == 'unigram':\n",
    "        unigram_vocab = (CountVectorizer(ngram_range=(1,1), stop_words='english')\n",
    "                        .fit(df.loc[:, 'text']))\n",
    "        return unigram_vocab.transform(x_df)\n",
    "        \n",
    "    elif str == 'bigram':\n",
    "        bigram_vocab = (CountVectorizer(ngram_range = (2, 2), stop_words='english')\n",
    "                        .fit(df.loc[:, 'text']))\n",
    "        return bigram_vocab.transform(x_df)\n",
    "    else: \n",
    "        trigram_vocab = (CountVectorizer(ngram_range = (3, 3), stop_words='english')\n",
    "                        .fit(df.loc[:, 'text']))\n",
    "        return trigram_vocab.transform(x_df)\n",
    "    \n",
    "def model_to_acuracy(model,x_train, x_test, y_train, y_test, combo):\n",
    "    \"\"\"\n",
    "    This function takes in the train and test data each variation, \n",
    "    visualizes, calculates model prediction, and returns accuracy score as a numpy int.\n",
    "    \"\"\"\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    predmnb = model.predict(x_test)\n",
    "    y = pd.concat([y_train, y_test])\n",
    "\n",
    "    #accuracy score only for even data\n",
    "    if y.value_counts().nunique() == 1:\n",
    "        print()\n",
    "        score = round(accuracy_score(y_test, predmnb) * 100, 2)\n",
    "        print(combo, \"Accuracy Score:\", score)\n",
    "\n",
    "    #f1 for uneven data \n",
    "    else:\n",
    "        print()\n",
    "        score = round(f1_score(y_test, predmnb, average='weighted') * 100, 2)\n",
    "        print(combo, \"f1_score:\", score)\n",
    "\n",
    "    print()\n",
    "    print(combo, \"Classification Report:\")\n",
    "    print(classification_report(y_test, predmnb))\n",
    "    return score\n",
    "\n",
    "def hyper_tuning(yelp_sample_equal, yelp_sample_unequal, model, hyper_combo, model_name):\n",
    "    \"\"\"\n",
    "    This function calculates the accuracy score for each variation of \n",
    "    hyperpermeters for a given model\n",
    "    \"\"\"\n",
    "\n",
    "    score_lst = []\n",
    "    time_lst = []\n",
    "    print()\n",
    "    print(model_name)\n",
    "    for tup in hyper_combo:\n",
    "        \n",
    "        star, gram, equal = tup\n",
    "\n",
    "        if equal == 'equal':\n",
    "\n",
    "            yelp_classify_equal = yelp_sample_equal.loc[:, ['stars', 'text']]\n",
    "            star_class_df = star_df(star, yelp_classify_equal)\n",
    "            x_df = n_gram_df(gram, star_class_df)\n",
    "        else: \n",
    "            yelp_classify_unequal = yelp_sample_unequal.loc[:, ['stars', 'text']]\n",
    "            star_class_df = star_df(star, yelp_classify_unequal)\n",
    "            x_df = n_gram_df(gram, star_class_df)\n",
    "\n",
    "        y_df = star_class_df['stars']\n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x_df, y_df,\n",
    "                                                            test_size=0.2, \n",
    "                                                            random_state=101)\n",
    "        start_time = time.time()\n",
    "        score = model_to_acuracy(model,x_train, x_test, y_train, y_test, tup)\n",
    "        end_time = time.time()\n",
    "        score_lst.append(score)\n",
    "        time_lst.append((float(end_time) - float(start_time)) / float(60))\n",
    "        print('Runtime in minutes: ', (float(end_time) - float(start_time)) / float(60))\n",
    "\n",
    "    return score_lst, time_lst\n",
    "\n",
    "score, time_lst_nb = hyper_tuning(yelp_sample_equal, \n",
    "                                  yelp_sample_unequal, \n",
    "                                  MultinomialNB(), \n",
    "                                  combo,\n",
    "                                  \"Multinomial Naive Bayes\")\n",
    "\n",
    "dt_score, time_lst_dt = hyper_tuning(yelp_sample_equal,\n",
    "                                     yelp_sample_unequal, \n",
    "                                     DecisionTreeClassifier(), \n",
    "                                     brand_new_combo,\n",
    "                                     \"Decision Tree Classifier\")\n",
    "\n",
    "rf_score, time_lst_rf  = hyper_tuning(yelp_sample_equal, \n",
    "                                      yelp_sample_unequal, \n",
    "                                      RandomForestClassifier(), \n",
    "                                      brand_new_combo,\n",
    "                                      \"Random Forest Classifier\")\n",
    "\n",
    "var_holder = {}\n",
    "max_iter_list = [100,1000,10000] \n",
    "\n",
    "for iter in max_iter_list:\n",
    "    (var_holder['lr_score_' + str(iter)], \n",
    "     var_holder['time_lst_' + str(iter)]) = hyper_tuning(yelp_sample_equal, \n",
    "                                                         yelp_sample_unequal, \n",
    "                                                         LogisticRegression(max_iter=iter), \n",
    "                                                         new_combo,\n",
    "                                                         \"Logistic Regression: \" + str(iter) + \" Iterations\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
